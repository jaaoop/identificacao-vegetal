{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Plant_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CuSWoRSC_Ok"
      },
      "source": [
        "# RASPlant\n",
        "\n",
        "> Objetivo: Desenvolver uma rede neural capaz de identificar plantas alimentícias não convencionais (PANCs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcyOqQK1DZa-"
      },
      "source": [
        "# Bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiKs-jj_wZy-"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "import os\n",
        "import cv2\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nRNmbRSMgcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "230eda1b-302e-4907-c2d1-9f949597f966"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kwYb2kBDtdC"
      },
      "source": [
        "# Preparação do Dataset\r\n",
        "\r\n",
        "> O bloco abaixo irá realizar a randomização e separação do dataset em duas pastas (Training e Testing) com uma determinada proporção especificada no código.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SshhTEaP_ejD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9005a9cd-6bdd-4fca-ba1a-937b8621a5fe"
      },
      "source": [
        "#Definiu-se algumas variáveis importantes para blocos futuros\n",
        "class_qtd=[]\n",
        "num_class=0\n",
        "\n",
        "#Função responsável por criar todas as pastas do dataset no drive\n",
        "def cria_diretorio(path):\n",
        "  if not os.path.exists(path):\n",
        "      os.mkdir(path)\n",
        "      print(\"Diretório \"+path+\" criado com sucesso\")\n",
        "  else:\n",
        "      print(\"Diretório \"+path+\" já foi criado\")\n",
        "\n",
        "#Esta função realiza, além da verificação da integridade de cada imagem, a randomização e separação do dataset em duas pastas \n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    content=os.listdir(SOURCE)\n",
        "    content=random.sample(content,len(content))\n",
        "    class_qtd.append(len(content))\n",
        "    for n,fname in enumerate(content):\n",
        "        if(n<(SPLIT_SIZE*len(content)) and os.path.getsize(f\"{SOURCE}/{fname}\")!=0):\n",
        "            copyfile(f\"{SOURCE}/{fname}\", f\"{TRAINING}/{fname}\")\n",
        "        if(n>=(SPLIT_SIZE*len(content)) and os.path.getsize(f\"{SOURCE}/{fname}\")!=0):\n",
        "            copyfile(f\"{SOURCE}/{fname}\", f\"{TESTING}/{fname}\")\n",
        "\n",
        "try:\n",
        "    #Nesta etapa, será necessário definir o endereço do diretório no Drive que contenha o Dataset a ser preparado\n",
        "    #Atente-se em colocar o endereço da pasta raiz e não um de seus sub-diretórios\n",
        "    old_base_dir='/content/drive/My Drive/Datasets/PANCS_200'\n",
        "    #Coloque um destino para o novo diretório que será gerado para o Dataset após sua preparação\n",
        "    base_dir='/content/drive/My Drive/Datasets/PANCS_10/'\n",
        "\n",
        "    #Com o novo destino (base_dir), cria-se um novo diretório contendo as pastas Training e Testing\n",
        "    cria_diretorio(base_dir)\n",
        "    train_dir=os.path.join(base_dir, 'Training')\n",
        "    cria_diretorio(train_dir)\n",
        "    test_dir=os.path.join(base_dir, 'Testing')\n",
        "    cria_diretorio(test_dir)\n",
        "\n",
        "    #Com base no diretório original (old_base_dir) do dataset, obtem-se o nome de todos os labels\n",
        "    labels=os.listdir(old_base_dir)\n",
        "    labels.sort()\n",
        "    num_class=len(labels)\n",
        "\n",
        "    #Defini-se aqui a proporção de separação do Dataset\n",
        "    split_size = .9  #90% para training e 10% para validation\n",
        "\n",
        "    #Para cada label será criado uma pasta tanto em Training como em Testing, nas quais serão colocadas, de forma randômica e na proporção\n",
        "    #estabelecida, as imagens contidas na pasta do Dataset original (old_base_dir)\n",
        "    for label in labels:\n",
        "      cria_diretorio(f\"{train_dir}/{label}\")\n",
        "      cria_diretorio(f\"{test_dir}/{label}\")\n",
        "      #split_data(f\"{old_base_dir}/{label}\", f\"{train_dir}/{label}\", f\"{test_dir}/{label}\", split_size)\n",
        "\n",
        "except OSError:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/ já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Training já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Testing já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Training/Araruta já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Testing/Araruta já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Training/Beldroegão já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Testing/Beldroegão já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Training/Capiçoba já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Testing/Capiçoba já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Training/Capuchina já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Testing/Capuchina já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Training/Caruru já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Testing/Caruru já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Training/Ora-pro-nóbis já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Testing/Ora-pro-nóbis já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Training/Peixinho já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Testing/Peixinho já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Training/Taioba já foi criado\n",
            "Diretório /content/drive/My Drive/Datasets/PANCS_10/Testing/Taioba já foi criado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81ZpIQ8Tv_M4"
      },
      "source": [
        "# Balanceamento de Classes\r\n",
        "\r\n",
        "\r\n",
        "> O bloco abaixo irá atribuir um peso maior para classes com menos imagens, visando promover uma menor disparidade entre as diferentes classes a serem analisadas. Ao final, será gerado uma lista contendo o peso de cada classe, a qual será utilizada pela rede.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eQ-ZbaMv_nm",
        "outputId": "fdc911a1-ff5a-4e01-985c-25c78fa87f37"
      },
      "source": [
        "class_weights={}\r\n",
        "for n in range(len(class_qtd)):\r\n",
        "  class_weights[n]=round(max(class_qtd)/class_qtd[n],2)\r\n",
        "\r\n",
        "print(class_qtd)\r\n",
        "print(class_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[60, 60, 192, 203, 173, 115, 56, 216]\n",
            "{0: 3.6, 1: 3.6, 2: 1.12, 3: 1.06, 4: 1.25, 5: 1.88, 6: 3.86, 7: 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyzODXTB8qyD"
      },
      "source": [
        "class_weights={0: 3.6, 1: 3.6, 2: 1.12, 3: 1.06, 4: 1.25, 5: 1.88, 6: 3.86, 7: 1.0}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1euQ7jQYIo0"
      },
      "source": [
        "# Condições de Treinamento\r\n",
        "\r\n",
        "\r\n",
        "> Defini-se aqui algumas variáveis que serão importantes na realização de sucessivos testes para otimizar a rede.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVjpQJA7YMUt"
      },
      "source": [
        "batch_size=16\r\n",
        "num_epochs=600"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZHezS1oDkpt"
      },
      "source": [
        "# Data Augmentation\r\n",
        "\r\n",
        "\r\n",
        "> Data Augmentation é um método utilizado para reduzir overfitting, na qual as imagens do dataset sofrem pequenas mudanças a fim de aumentar a varaibilidade de suas características, resultando em um conjunto de dados do dataset mais generalizado. Assim, ao fazer uso deste método, consegue-se aumentar a generalidade do modelo de rede neural a ser treinado, contribuindo para obtenção de melhores resultados no conjunto de dados de testes.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "163elGntJYyK",
        "outputId": "d135adb9-56e5-4648-fb50-930815ba27f5"
      },
      "source": [
        "#Em imageDataGenerator serão definidos os parâmetros do Data Augmentation a serem aplicados no conjunto de dados de treino\n",
        "TRAINING_DIR = train_dir\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      brightness_range=(0.2,1.0),\n",
        "\t    rotation_range=30,\n",
        "      #width_shift_range=0.2,\n",
        "      #height_shift_range=0.2,\n",
        "      #shear_range=0.2,\n",
        "      zoom_range=0.15,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "#No conjunto de dados de teste não aplica-se Data augmentation, realiza-se apenas a divisão dos valores de cada pixel por 255, pois\n",
        "#a rede trabalha melhor com valores entre 0 e 1.\n",
        "VALIDATION_DIR = test_dir\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "#As funções a seguir irão aplicar os parâmetros definidos acima para os conjuntos de Treino e Teste\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(224,224), #Definiu-se um tamanho padrão para as imagens de (224,224)\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=batch_size\n",
        ")\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(224,224),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "label_map = (train_generator.class_indices)\n",
        "print(label_map)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 970 images belonging to 8 classes.\n",
            "Found 105 images belonging to 8 classes.\n",
            "{'Araruta': 0, 'Beldroegão': 1, 'Capiçoba': 2, 'Capuchina': 3, 'Caruru': 4, 'Ora-pro-nóbis': 5, 'Peixinho': 6, 'Taioba': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNuuvI4hm0kK"
      },
      "source": [
        "# Callback\r\n",
        "\r\n",
        "\r\n",
        "> Um callback trata-se de um cojunto de funções que serão aplicadas quando um determinado estágio do treinamento da rede neural for alcançado. Como o dataset utilizado para este projeto está desbalanceado, utilizou-se o Recall como a métrica mais importante e, consequentemente, definimos um valor mínimo de 80% a ser alcançado por ele antes de encerrarmos o treino.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6rgA8KOm0FL"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback): \r\n",
        "    def on_epoch_end(self, epoch, logs={}): \r\n",
        "        if(logs.get('recall') > 0.8):   \r\n",
        "          print(\"\\nWe have reached %2.2f%% recall, so we will stopping training.\" %(logs.get('recall')*100))   \r\n",
        "          self.model.stop_training = True\r\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6rjHuquCorD"
      },
      "source": [
        "# VGG16 com pesos da imagenet\r\n",
        "\r\n",
        "\r\n",
        "> Para este projeto empregou-se a técnica de Transfer Learning, na qual utiliza-se os pesos de uma ou mais camadas de uma rede pré-treinada para treinar uma nova rede. Para um melhor resultado, será utilizado os pesos da ImageNet como um Feature Extractor no modelo, ou seja, remove-se o topo do modelo já treinado, adiciona-se novas camadas e somente elas serão treinadas. Assim, a rede se beneficiará de um modelo com camadas iniciais suficientemente  treinadas com uma ampla variedade de imagens, enquanto as camadas finais se ajustam ao novo Dataset.\r\n",
        "\r\n",
        "> Além disso, optamos por utilizar uma arquitetura de rede conhecida como VGG16, a qual apresentou os melhores resultados durante a fase de testes. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMzMAXnFJkOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d89b0f-7f9c-4984-ba8b-c9dda02e105e"
      },
      "source": [
        "#Baixa a arquitetura da rede VGG16 com os pesos da ImageNet e remove as camadas finais\n",
        "model = VGG16(include_top=False, weights='imagenet',input_shape=(224,224,3))\n",
        "\n",
        "#Congela todas as camadas da rede\n",
        "for layer in model.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "#Cria-se as novas camadas finais a serem treinadas\n",
        "headModel = model.output\n",
        "headModel = Flatten()(headModel)\n",
        "headModel = Dense(1024, activation='relu')(headModel) #512\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(num_class, activation='softmax')(headModel)\n",
        "\n",
        "#Integra a rede com os pesos da ImageNet com o novo topo do modelo\n",
        "model = Model(inputs=model.inputs, outputs=headModel)\n",
        "\n",
        "#Configura de treino\n",
        "model.summary()\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy','Precision','Recall'])\n",
        "history = model.fit(train_generator, epochs=num_epochs, validation_data = validation_generator, verbose = 1,class_weight=class_weights,callbacks=[callbacks])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 40,414,024\n",
            "Trainable params: 25,699,336\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "61/61 [==============================] - 299s 5s/step - loss: 12.9582 - accuracy: 0.1736 - precision: 0.1846 - recall: 0.1562 - val_loss: 1.6911 - val_accuracy: 0.3238 - val_precision: 0.4545 - val_recall: 0.1429\n",
            "Epoch 2/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 2.9218 - accuracy: 0.3598 - precision: 0.5378 - recall: 0.1835 - val_loss: 1.2545 - val_accuracy: 0.6000 - val_precision: 1.0000 - val_recall: 0.2095\n",
            "Epoch 3/600\n",
            "61/61 [==============================] - 16s 264ms/step - loss: 2.5735 - accuracy: 0.3912 - precision: 0.6880 - recall: 0.1655 - val_loss: 1.1701 - val_accuracy: 0.6000 - val_precision: 0.7778 - val_recall: 0.2667\n",
            "Epoch 4/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 2.5956 - accuracy: 0.3904 - precision: 0.6365 - recall: 0.1999 - val_loss: 1.1850 - val_accuracy: 0.5619 - val_precision: 0.8421 - val_recall: 0.3048\n",
            "Epoch 5/600\n",
            "61/61 [==============================] - 16s 269ms/step - loss: 2.2884 - accuracy: 0.4262 - precision: 0.6895 - recall: 0.2196 - val_loss: 1.1663 - val_accuracy: 0.5429 - val_precision: 0.7143 - val_recall: 0.2857\n",
            "Epoch 6/600\n",
            "61/61 [==============================] - 16s 267ms/step - loss: 2.3834 - accuracy: 0.4482 - precision: 0.6615 - recall: 0.2384 - val_loss: 1.0244 - val_accuracy: 0.6190 - val_precision: 0.8182 - val_recall: 0.4286\n",
            "Epoch 7/600\n",
            "61/61 [==============================] - 16s 264ms/step - loss: 2.0905 - accuracy: 0.5058 - precision: 0.7282 - recall: 0.2924 - val_loss: 1.0128 - val_accuracy: 0.6571 - val_precision: 0.9000 - val_recall: 0.4286\n",
            "Epoch 8/600\n",
            "61/61 [==============================] - 16s 265ms/step - loss: 2.1433 - accuracy: 0.4855 - precision: 0.7437 - recall: 0.2682 - val_loss: 1.0068 - val_accuracy: 0.6571 - val_precision: 0.8088 - val_recall: 0.5238\n",
            "Epoch 9/600\n",
            "61/61 [==============================] - 17s 273ms/step - loss: 1.8848 - accuracy: 0.5282 - precision: 0.7308 - recall: 0.3316 - val_loss: 0.8951 - val_accuracy: 0.6381 - val_precision: 0.8033 - val_recall: 0.4667\n",
            "Epoch 10/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.9996 - accuracy: 0.5284 - precision: 0.7150 - recall: 0.3489 - val_loss: 0.9056 - val_accuracy: 0.6095 - val_precision: 0.8793 - val_recall: 0.4857\n",
            "Epoch 11/600\n",
            "61/61 [==============================] - 16s 267ms/step - loss: 1.9184 - accuracy: 0.5695 - precision: 0.8056 - recall: 0.3555 - val_loss: 0.9991 - val_accuracy: 0.6000 - val_precision: 0.7313 - val_recall: 0.4667\n",
            "Epoch 12/600\n",
            "61/61 [==============================] - 16s 265ms/step - loss: 1.9892 - accuracy: 0.5546 - precision: 0.7288 - recall: 0.3469 - val_loss: 0.9712 - val_accuracy: 0.6571 - val_precision: 0.7313 - val_recall: 0.4667\n",
            "Epoch 13/600\n",
            "61/61 [==============================] - 16s 264ms/step - loss: 1.8275 - accuracy: 0.5745 - precision: 0.7458 - recall: 0.3941 - val_loss: 0.7941 - val_accuracy: 0.6762 - val_precision: 0.8028 - val_recall: 0.5429\n",
            "Epoch 14/600\n",
            "61/61 [==============================] - 16s 263ms/step - loss: 1.7972 - accuracy: 0.5746 - precision: 0.7430 - recall: 0.4257 - val_loss: 0.9293 - val_accuracy: 0.6095 - val_precision: 0.7778 - val_recall: 0.4667\n",
            "Epoch 15/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.7291 - accuracy: 0.5312 - precision: 0.7635 - recall: 0.3857 - val_loss: 0.8213 - val_accuracy: 0.7238 - val_precision: 0.8382 - val_recall: 0.5429\n",
            "Epoch 16/600\n",
            "61/61 [==============================] - 16s 264ms/step - loss: 1.7338 - accuracy: 0.5677 - precision: 0.7070 - recall: 0.4062 - val_loss: 0.9158 - val_accuracy: 0.6476 - val_precision: 0.7105 - val_recall: 0.5143\n",
            "Epoch 17/600\n",
            "61/61 [==============================] - 16s 263ms/step - loss: 1.8035 - accuracy: 0.5494 - precision: 0.7324 - recall: 0.3979 - val_loss: 0.8064 - val_accuracy: 0.6857 - val_precision: 0.8356 - val_recall: 0.5810\n",
            "Epoch 18/600\n",
            "61/61 [==============================] - 16s 262ms/step - loss: 1.7192 - accuracy: 0.6103 - precision: 0.7996 - recall: 0.4136 - val_loss: 1.0283 - val_accuracy: 0.6476 - val_precision: 0.8636 - val_recall: 0.3619\n",
            "Epoch 19/600\n",
            "61/61 [==============================] - 16s 265ms/step - loss: 1.8315 - accuracy: 0.5588 - precision: 0.7687 - recall: 0.3555 - val_loss: 0.8101 - val_accuracy: 0.7524 - val_precision: 0.9298 - val_recall: 0.5048\n",
            "Epoch 20/600\n",
            "61/61 [==============================] - 16s 267ms/step - loss: 1.7833 - accuracy: 0.5782 - precision: 0.8019 - recall: 0.3759 - val_loss: 0.9323 - val_accuracy: 0.6571 - val_precision: 0.8545 - val_recall: 0.4476\n",
            "Epoch 21/600\n",
            "61/61 [==============================] - 16s 262ms/step - loss: 1.8811 - accuracy: 0.5414 - precision: 0.8127 - recall: 0.3580 - val_loss: 0.7921 - val_accuracy: 0.7333 - val_precision: 0.9231 - val_recall: 0.5714\n",
            "Epoch 22/600\n",
            "61/61 [==============================] - 16s 264ms/step - loss: 1.9712 - accuracy: 0.5173 - precision: 0.7985 - recall: 0.3443 - val_loss: 0.7765 - val_accuracy: 0.7429 - val_precision: 0.8986 - val_recall: 0.5905\n",
            "Epoch 23/600\n",
            "61/61 [==============================] - 16s 263ms/step - loss: 1.7907 - accuracy: 0.5676 - precision: 0.7790 - recall: 0.3943 - val_loss: 0.7101 - val_accuracy: 0.8000 - val_precision: 0.8590 - val_recall: 0.6381\n",
            "Epoch 24/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.6662 - accuracy: 0.6038 - precision: 0.7367 - recall: 0.4168 - val_loss: 0.8622 - val_accuracy: 0.7238 - val_precision: 0.9615 - val_recall: 0.4762\n",
            "Epoch 25/600\n",
            "61/61 [==============================] - 16s 265ms/step - loss: 1.9673 - accuracy: 0.5402 - precision: 0.7495 - recall: 0.3335 - val_loss: 0.7959 - val_accuracy: 0.7714 - val_precision: 0.9219 - val_recall: 0.5619\n",
            "Epoch 26/600\n",
            "61/61 [==============================] - 16s 263ms/step - loss: 1.7059 - accuracy: 0.5936 - precision: 0.7985 - recall: 0.4334 - val_loss: 0.7249 - val_accuracy: 0.7524 - val_precision: 0.8919 - val_recall: 0.6286\n",
            "Epoch 27/600\n",
            "61/61 [==============================] - 16s 263ms/step - loss: 1.7556 - accuracy: 0.5522 - precision: 0.7482 - recall: 0.4052 - val_loss: 0.7015 - val_accuracy: 0.7905 - val_precision: 0.8831 - val_recall: 0.6476\n",
            "Epoch 28/600\n",
            "61/61 [==============================] - 17s 271ms/step - loss: 1.5701 - accuracy: 0.5896 - precision: 0.7627 - recall: 0.4430 - val_loss: 0.7250 - val_accuracy: 0.6952 - val_precision: 0.8289 - val_recall: 0.6000\n",
            "Epoch 29/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.6590 - accuracy: 0.5941 - precision: 0.7826 - recall: 0.4341 - val_loss: 0.8443 - val_accuracy: 0.7333 - val_precision: 0.7808 - val_recall: 0.5429\n",
            "Epoch 30/600\n",
            "61/61 [==============================] - 16s 265ms/step - loss: 1.7300 - accuracy: 0.5759 - precision: 0.7743 - recall: 0.4134 - val_loss: 0.7594 - val_accuracy: 0.7524 - val_precision: 0.8718 - val_recall: 0.6476\n",
            "Epoch 31/600\n",
            "61/61 [==============================] - 16s 261ms/step - loss: 1.6103 - accuracy: 0.5553 - precision: 0.7504 - recall: 0.4162 - val_loss: 0.7321 - val_accuracy: 0.7238 - val_precision: 0.8571 - val_recall: 0.6857\n",
            "Epoch 32/600\n",
            "61/61 [==============================] - 16s 263ms/step - loss: 1.5931 - accuracy: 0.5948 - precision: 0.7556 - recall: 0.4708 - val_loss: 0.7679 - val_accuracy: 0.7333 - val_precision: 0.8250 - val_recall: 0.6286\n",
            "Epoch 33/600\n",
            "61/61 [==============================] - 17s 273ms/step - loss: 1.5572 - accuracy: 0.5735 - precision: 0.7999 - recall: 0.4201 - val_loss: 0.6401 - val_accuracy: 0.7619 - val_precision: 0.8987 - val_recall: 0.6762\n",
            "Epoch 34/600\n",
            "61/61 [==============================] - 17s 275ms/step - loss: 1.5130 - accuracy: 0.6198 - precision: 0.7919 - recall: 0.4703 - val_loss: 0.7438 - val_accuracy: 0.7619 - val_precision: 0.8831 - val_recall: 0.6476\n",
            "Epoch 35/600\n",
            "61/61 [==============================] - 17s 278ms/step - loss: 1.5699 - accuracy: 0.5827 - precision: 0.7484 - recall: 0.4257 - val_loss: 0.8299 - val_accuracy: 0.7048 - val_precision: 0.7941 - val_recall: 0.5143\n",
            "Epoch 36/600\n",
            "61/61 [==============================] - 16s 268ms/step - loss: 1.5169 - accuracy: 0.6261 - precision: 0.8337 - recall: 0.4330 - val_loss: 0.8334 - val_accuracy: 0.6952 - val_precision: 0.8571 - val_recall: 0.5714\n",
            "Epoch 37/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.5806 - accuracy: 0.5877 - precision: 0.7785 - recall: 0.4267 - val_loss: 0.7395 - val_accuracy: 0.7238 - val_precision: 0.8481 - val_recall: 0.6381\n",
            "Epoch 38/600\n",
            "61/61 [==============================] - 16s 267ms/step - loss: 1.5987 - accuracy: 0.6070 - precision: 0.8055 - recall: 0.4244 - val_loss: 0.7279 - val_accuracy: 0.7524 - val_precision: 0.7802 - val_recall: 0.6762\n",
            "Epoch 39/600\n",
            "61/61 [==============================] - 16s 268ms/step - loss: 1.8344 - accuracy: 0.5475 - precision: 0.7730 - recall: 0.3903 - val_loss: 0.7336 - val_accuracy: 0.7333 - val_precision: 0.9143 - val_recall: 0.6095\n",
            "Epoch 40/600\n",
            "61/61 [==============================] - 16s 268ms/step - loss: 1.6595 - accuracy: 0.6254 - precision: 0.8128 - recall: 0.4434 - val_loss: 0.7830 - val_accuracy: 0.7429 - val_precision: 0.8182 - val_recall: 0.6857\n",
            "Epoch 41/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.7722 - accuracy: 0.5799 - precision: 0.7702 - recall: 0.4382 - val_loss: 0.7220 - val_accuracy: 0.7048 - val_precision: 0.8228 - val_recall: 0.6190\n",
            "Epoch 42/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.5406 - accuracy: 0.5842 - precision: 0.7778 - recall: 0.4331 - val_loss: 0.7114 - val_accuracy: 0.7524 - val_precision: 0.8481 - val_recall: 0.6381\n",
            "Epoch 43/600\n",
            "61/61 [==============================] - 16s 269ms/step - loss: 1.4550 - accuracy: 0.6136 - precision: 0.7931 - recall: 0.4882 - val_loss: 0.7495 - val_accuracy: 0.7238 - val_precision: 0.9000 - val_recall: 0.6000\n",
            "Epoch 44/600\n",
            "61/61 [==============================] - 16s 267ms/step - loss: 1.5550 - accuracy: 0.6107 - precision: 0.7970 - recall: 0.4613 - val_loss: 0.7466 - val_accuracy: 0.7333 - val_precision: 0.8125 - val_recall: 0.6190\n",
            "Epoch 45/600\n",
            "61/61 [==============================] - 16s 267ms/step - loss: 1.3997 - accuracy: 0.6378 - precision: 0.7773 - recall: 0.5270 - val_loss: 0.7469 - val_accuracy: 0.7524 - val_precision: 0.8022 - val_recall: 0.6952\n",
            "Epoch 46/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.5201 - accuracy: 0.6335 - precision: 0.8074 - recall: 0.4960 - val_loss: 0.7970 - val_accuracy: 0.7238 - val_precision: 0.7912 - val_recall: 0.6857\n",
            "Epoch 47/600\n",
            "61/61 [==============================] - 17s 272ms/step - loss: 1.4275 - accuracy: 0.6338 - precision: 0.7772 - recall: 0.4960 - val_loss: 0.7041 - val_accuracy: 0.7429 - val_precision: 0.8118 - val_recall: 0.6571\n",
            "Epoch 48/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.4416 - accuracy: 0.6008 - precision: 0.7925 - recall: 0.4781 - val_loss: 0.8051 - val_accuracy: 0.7429 - val_precision: 0.8049 - val_recall: 0.6286\n",
            "Epoch 49/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.5347 - accuracy: 0.5631 - precision: 0.7712 - recall: 0.4275 - val_loss: 0.7562 - val_accuracy: 0.7619 - val_precision: 0.7865 - val_recall: 0.6667\n",
            "Epoch 50/600\n",
            "61/61 [==============================] - 16s 267ms/step - loss: 1.4507 - accuracy: 0.6432 - precision: 0.8011 - recall: 0.4724 - val_loss: 0.7639 - val_accuracy: 0.7333 - val_precision: 0.8313 - val_recall: 0.6571\n",
            "Epoch 51/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.3310 - accuracy: 0.6185 - precision: 0.7809 - recall: 0.4924 - val_loss: 0.7370 - val_accuracy: 0.7333 - val_precision: 0.7978 - val_recall: 0.6762\n",
            "Epoch 52/600\n",
            "61/61 [==============================] - 16s 269ms/step - loss: 1.5260 - accuracy: 0.6189 - precision: 0.7641 - recall: 0.4871 - val_loss: 0.7807 - val_accuracy: 0.7238 - val_precision: 0.7857 - val_recall: 0.6286\n",
            "Epoch 53/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.4113 - accuracy: 0.6575 - precision: 0.8075 - recall: 0.5052 - val_loss: 0.7792 - val_accuracy: 0.6857 - val_precision: 0.7683 - val_recall: 0.6000\n",
            "Epoch 54/600\n",
            "61/61 [==============================] - 16s 270ms/step - loss: 1.3756 - accuracy: 0.6255 - precision: 0.8059 - recall: 0.5181 - val_loss: 0.8321 - val_accuracy: 0.7238 - val_precision: 0.7935 - val_recall: 0.6952\n",
            "Epoch 55/600\n",
            "61/61 [==============================] - 16s 269ms/step - loss: 1.3884 - accuracy: 0.6396 - precision: 0.8374 - recall: 0.5259 - val_loss: 0.8892 - val_accuracy: 0.6476 - val_precision: 0.7442 - val_recall: 0.6095\n",
            "Epoch 56/600\n",
            "61/61 [==============================] - 16s 267ms/step - loss: 1.4467 - accuracy: 0.6504 - precision: 0.8147 - recall: 0.5349 - val_loss: 0.7107 - val_accuracy: 0.7619 - val_precision: 0.7742 - val_recall: 0.6857\n",
            "Epoch 57/600\n",
            "61/61 [==============================] - 17s 272ms/step - loss: 1.3935 - accuracy: 0.6290 - precision: 0.7984 - recall: 0.4939 - val_loss: 0.7129 - val_accuracy: 0.7333 - val_precision: 0.7849 - val_recall: 0.6952\n",
            "Epoch 58/600\n",
            "61/61 [==============================] - 16s 268ms/step - loss: 1.4519 - accuracy: 0.6498 - precision: 0.7871 - recall: 0.5428 - val_loss: 0.7349 - val_accuracy: 0.7238 - val_precision: 0.7684 - val_recall: 0.6952\n",
            "Epoch 59/600\n",
            "61/61 [==============================] - 16s 267ms/step - loss: 1.4430 - accuracy: 0.6577 - precision: 0.8038 - recall: 0.5180 - val_loss: 0.8086 - val_accuracy: 0.7429 - val_precision: 0.8000 - val_recall: 0.6857\n",
            "Epoch 60/600\n",
            "61/61 [==============================] - 16s 269ms/step - loss: 1.4900 - accuracy: 0.6445 - precision: 0.7865 - recall: 0.5237 - val_loss: 0.7907 - val_accuracy: 0.7429 - val_precision: 0.7979 - val_recall: 0.7143\n",
            "Epoch 61/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.3285 - accuracy: 0.6593 - precision: 0.8042 - recall: 0.5111 - val_loss: 0.7744 - val_accuracy: 0.7333 - val_precision: 0.8506 - val_recall: 0.7048\n",
            "Epoch 62/600\n",
            "61/61 [==============================] - 16s 269ms/step - loss: 1.3810 - accuracy: 0.6806 - precision: 0.8237 - recall: 0.5272 - val_loss: 0.7040 - val_accuracy: 0.7619 - val_precision: 0.7978 - val_recall: 0.6762\n",
            "Epoch 63/600\n",
            "61/61 [==============================] - 16s 267ms/step - loss: 1.3924 - accuracy: 0.6460 - precision: 0.8125 - recall: 0.5212 - val_loss: 0.6954 - val_accuracy: 0.7619 - val_precision: 0.8462 - val_recall: 0.7333\n",
            "Epoch 64/600\n",
            "61/61 [==============================] - 16s 267ms/step - loss: 1.2087 - accuracy: 0.6928 - precision: 0.8612 - recall: 0.5789 - val_loss: 0.8356 - val_accuracy: 0.7524 - val_precision: 0.7732 - val_recall: 0.7143\n",
            "Epoch 65/600\n",
            "61/61 [==============================] - 16s 264ms/step - loss: 1.2169 - accuracy: 0.6948 - precision: 0.8104 - recall: 0.5845 - val_loss: 0.7818 - val_accuracy: 0.7333 - val_precision: 0.8395 - val_recall: 0.6476\n",
            "Epoch 66/600\n",
            "61/61 [==============================] - 17s 270ms/step - loss: 1.2811 - accuracy: 0.6387 - precision: 0.8114 - recall: 0.5176 - val_loss: 0.6477 - val_accuracy: 0.7810 - val_precision: 0.8211 - val_recall: 0.7429\n",
            "Epoch 67/600\n",
            "61/61 [==============================] - 17s 274ms/step - loss: 1.2766 - accuracy: 0.7084 - precision: 0.8331 - recall: 0.5503 - val_loss: 0.8052 - val_accuracy: 0.7238 - val_precision: 0.8000 - val_recall: 0.6476\n",
            "Epoch 68/600\n",
            "61/61 [==============================] - 17s 275ms/step - loss: 1.2379 - accuracy: 0.6841 - precision: 0.8172 - recall: 0.5689 - val_loss: 0.6768 - val_accuracy: 0.8000 - val_precision: 0.8298 - val_recall: 0.7429\n",
            "Epoch 69/600\n",
            "61/61 [==============================] - 17s 275ms/step - loss: 1.2119 - accuracy: 0.6950 - precision: 0.8357 - recall: 0.5694 - val_loss: 0.6932 - val_accuracy: 0.7810 - val_precision: 0.8229 - val_recall: 0.7524\n",
            "Epoch 70/600\n",
            "61/61 [==============================] - 16s 267ms/step - loss: 1.3429 - accuracy: 0.6625 - precision: 0.8144 - recall: 0.5631 - val_loss: 0.7332 - val_accuracy: 0.7619 - val_precision: 0.8021 - val_recall: 0.7333\n",
            "Epoch 71/600\n",
            "61/61 [==============================] - 16s 269ms/step - loss: 1.1616 - accuracy: 0.7348 - precision: 0.8300 - recall: 0.5980 - val_loss: 0.7090 - val_accuracy: 0.7905 - val_precision: 0.8229 - val_recall: 0.7524\n",
            "Epoch 72/600\n",
            "61/61 [==============================] - 16s 268ms/step - loss: 1.1953 - accuracy: 0.6826 - precision: 0.8123 - recall: 0.5815 - val_loss: 0.8080 - val_accuracy: 0.7143 - val_precision: 0.7849 - val_recall: 0.6952\n",
            "Epoch 73/600\n",
            "61/61 [==============================] - 16s 269ms/step - loss: 1.2391 - accuracy: 0.6853 - precision: 0.8104 - recall: 0.5577 - val_loss: 0.6785 - val_accuracy: 0.7810 - val_precision: 0.8444 - val_recall: 0.7238\n",
            "Epoch 74/600\n",
            "61/61 [==============================] - 16s 269ms/step - loss: 1.2776 - accuracy: 0.6977 - precision: 0.8464 - recall: 0.5476 - val_loss: 0.6901 - val_accuracy: 0.7714 - val_precision: 0.8588 - val_recall: 0.6952\n",
            "Epoch 75/600\n",
            "61/61 [==============================] - 17s 271ms/step - loss: 1.3568 - accuracy: 0.6835 - precision: 0.8247 - recall: 0.5598 - val_loss: 0.7606 - val_accuracy: 0.7333 - val_precision: 0.8333 - val_recall: 0.7143\n",
            "Epoch 76/600\n",
            "61/61 [==============================] - 16s 269ms/step - loss: 1.1405 - accuracy: 0.7148 - precision: 0.8214 - recall: 0.5885 - val_loss: 0.6950 - val_accuracy: 0.7429 - val_precision: 0.7789 - val_recall: 0.7048\n",
            "Epoch 77/600\n",
            "61/61 [==============================] - 16s 270ms/step - loss: 1.1532 - accuracy: 0.6890 - precision: 0.8348 - recall: 0.5743 - val_loss: 0.7052 - val_accuracy: 0.7714 - val_precision: 0.8100 - val_recall: 0.7714\n",
            "Epoch 78/600\n",
            "61/61 [==============================] - 16s 268ms/step - loss: 1.1074 - accuracy: 0.7030 - precision: 0.8267 - recall: 0.6197 - val_loss: 0.6144 - val_accuracy: 0.8095 - val_precision: 0.8229 - val_recall: 0.7524\n",
            "Epoch 79/600\n",
            "61/61 [==============================] - 16s 268ms/step - loss: 1.2060 - accuracy: 0.6734 - precision: 0.7927 - recall: 0.5681 - val_loss: 0.7306 - val_accuracy: 0.7714 - val_precision: 0.8261 - val_recall: 0.7238\n",
            "Epoch 80/600\n",
            "61/61 [==============================] - 16s 268ms/step - loss: 1.3082 - accuracy: 0.6820 - precision: 0.8175 - recall: 0.5662 - val_loss: 0.6124 - val_accuracy: 0.7810 - val_precision: 0.8242 - val_recall: 0.7143\n",
            "Epoch 81/600\n",
            "61/61 [==============================] - 16s 265ms/step - loss: 1.0853 - accuracy: 0.7154 - precision: 0.8614 - recall: 0.6054 - val_loss: 0.6900 - val_accuracy: 0.7524 - val_precision: 0.7979 - val_recall: 0.7143\n",
            "Epoch 82/600\n",
            "61/61 [==============================] - 16s 263ms/step - loss: 1.1695 - accuracy: 0.7051 - precision: 0.8517 - recall: 0.5766 - val_loss: 0.6823 - val_accuracy: 0.8190 - val_precision: 0.8283 - val_recall: 0.7810\n",
            "Epoch 83/600\n",
            "61/61 [==============================] - 16s 262ms/step - loss: 1.2321 - accuracy: 0.6746 - precision: 0.7997 - recall: 0.5913 - val_loss: 0.7346 - val_accuracy: 0.7238 - val_precision: 0.8090 - val_recall: 0.6857\n",
            "Epoch 84/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.1896 - accuracy: 0.7013 - precision: 0.8218 - recall: 0.6071 - val_loss: 0.7131 - val_accuracy: 0.8000 - val_precision: 0.8061 - val_recall: 0.7524\n",
            "Epoch 85/600\n",
            "61/61 [==============================] - 16s 269ms/step - loss: 1.1721 - accuracy: 0.6811 - precision: 0.8211 - recall: 0.5904 - val_loss: 0.7826 - val_accuracy: 0.7524 - val_precision: 0.8090 - val_recall: 0.6857\n",
            "Epoch 86/600\n",
            "61/61 [==============================] - 16s 262ms/step - loss: 1.2924 - accuracy: 0.6784 - precision: 0.7994 - recall: 0.5588 - val_loss: 0.5743 - val_accuracy: 0.7619 - val_precision: 0.8085 - val_recall: 0.7238\n",
            "Epoch 87/600\n",
            "61/61 [==============================] - 16s 263ms/step - loss: 1.1908 - accuracy: 0.7285 - precision: 0.8480 - recall: 0.5796 - val_loss: 0.6768 - val_accuracy: 0.7810 - val_precision: 0.8041 - val_recall: 0.7429\n",
            "Epoch 88/600\n",
            "61/61 [==============================] - 16s 262ms/step - loss: 1.0522 - accuracy: 0.7181 - precision: 0.8591 - recall: 0.6280 - val_loss: 0.6405 - val_accuracy: 0.7905 - val_precision: 0.8061 - val_recall: 0.7524\n",
            "Epoch 89/600\n",
            "61/61 [==============================] - 16s 264ms/step - loss: 1.1979 - accuracy: 0.6943 - precision: 0.8248 - recall: 0.5828 - val_loss: 0.5820 - val_accuracy: 0.7333 - val_precision: 0.7872 - val_recall: 0.7048\n",
            "Epoch 90/600\n",
            "61/61 [==============================] - 16s 262ms/step - loss: 1.3334 - accuracy: 0.6878 - precision: 0.8377 - recall: 0.5337 - val_loss: 0.6574 - val_accuracy: 0.7714 - val_precision: 0.8172 - val_recall: 0.7238\n",
            "Epoch 91/600\n",
            "61/61 [==============================] - 16s 259ms/step - loss: 1.2150 - accuracy: 0.7162 - precision: 0.8333 - recall: 0.5739 - val_loss: 0.6691 - val_accuracy: 0.7810 - val_precision: 0.7921 - val_recall: 0.7619\n",
            "Epoch 92/600\n",
            "61/61 [==============================] - 16s 261ms/step - loss: 1.0246 - accuracy: 0.7317 - precision: 0.8316 - recall: 0.6332 - val_loss: 0.6494 - val_accuracy: 0.7905 - val_precision: 0.8247 - val_recall: 0.7619\n",
            "Epoch 93/600\n",
            "61/61 [==============================] - 16s 262ms/step - loss: 1.0842 - accuracy: 0.7080 - precision: 0.8465 - recall: 0.5996 - val_loss: 0.6942 - val_accuracy: 0.7429 - val_precision: 0.7812 - val_recall: 0.7143\n",
            "Epoch 94/600\n",
            "61/61 [==============================] - 16s 262ms/step - loss: 1.1528 - accuracy: 0.7129 - precision: 0.8288 - recall: 0.6008 - val_loss: 0.7512 - val_accuracy: 0.7524 - val_precision: 0.8000 - val_recall: 0.6476\n",
            "Epoch 95/600\n",
            "61/61 [==============================] - 16s 264ms/step - loss: 1.1785 - accuracy: 0.6749 - precision: 0.8612 - recall: 0.5728 - val_loss: 0.6377 - val_accuracy: 0.7619 - val_precision: 0.8298 - val_recall: 0.7429\n",
            "Epoch 96/600\n",
            "61/61 [==============================] - 16s 261ms/step - loss: 1.3449 - accuracy: 0.6961 - precision: 0.8280 - recall: 0.5735 - val_loss: 0.5835 - val_accuracy: 0.8000 - val_precision: 0.8387 - val_recall: 0.7429\n",
            "Epoch 97/600\n",
            "61/61 [==============================] - 16s 262ms/step - loss: 1.0172 - accuracy: 0.7403 - precision: 0.8538 - recall: 0.6247 - val_loss: 0.6860 - val_accuracy: 0.7714 - val_precision: 0.8085 - val_recall: 0.7238\n",
            "Epoch 98/600\n",
            "61/61 [==============================] - 16s 263ms/step - loss: 1.0475 - accuracy: 0.7218 - precision: 0.8654 - recall: 0.6259 - val_loss: 0.6636 - val_accuracy: 0.7524 - val_precision: 0.8140 - val_recall: 0.6667\n",
            "Epoch 99/600\n",
            "61/61 [==============================] - 16s 264ms/step - loss: 1.1376 - accuracy: 0.6962 - precision: 0.8474 - recall: 0.5669 - val_loss: 0.6194 - val_accuracy: 0.7905 - val_precision: 0.7843 - val_recall: 0.7619\n",
            "Epoch 100/600\n",
            "61/61 [==============================] - 16s 261ms/step - loss: 0.9796 - accuracy: 0.7449 - precision: 0.8491 - recall: 0.6423 - val_loss: 0.6769 - val_accuracy: 0.7524 - val_precision: 0.7917 - val_recall: 0.7238\n",
            "Epoch 101/600\n",
            "61/61 [==============================] - 16s 258ms/step - loss: 1.1231 - accuracy: 0.7185 - precision: 0.8526 - recall: 0.6098 - val_loss: 0.6336 - val_accuracy: 0.7905 - val_precision: 0.8229 - val_recall: 0.7524\n",
            "Epoch 102/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.0466 - accuracy: 0.7199 - precision: 0.8231 - recall: 0.6289 - val_loss: 0.8223 - val_accuracy: 0.7429 - val_precision: 0.7835 - val_recall: 0.7238\n",
            "Epoch 103/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.0943 - accuracy: 0.7048 - precision: 0.8291 - recall: 0.6077 - val_loss: 0.7310 - val_accuracy: 0.7429 - val_precision: 0.7812 - val_recall: 0.7143\n",
            "Epoch 104/600\n",
            "61/61 [==============================] - 17s 276ms/step - loss: 1.0073 - accuracy: 0.7516 - precision: 0.8506 - recall: 0.6642 - val_loss: 0.6637 - val_accuracy: 0.7810 - val_precision: 0.8242 - val_recall: 0.7143\n",
            "Epoch 105/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 1.1353 - accuracy: 0.7036 - precision: 0.8218 - recall: 0.5919 - val_loss: 0.7620 - val_accuracy: 0.7619 - val_precision: 0.8000 - val_recall: 0.7238\n",
            "Epoch 106/600\n",
            "61/61 [==============================] - 16s 258ms/step - loss: 0.9786 - accuracy: 0.7708 - precision: 0.8678 - recall: 0.6529 - val_loss: 0.6763 - val_accuracy: 0.7333 - val_precision: 0.8105 - val_recall: 0.7333\n",
            "Epoch 107/600\n",
            "61/61 [==============================] - 16s 259ms/step - loss: 1.0940 - accuracy: 0.7270 - precision: 0.8486 - recall: 0.6433 - val_loss: 0.6917 - val_accuracy: 0.7714 - val_precision: 0.8163 - val_recall: 0.7619\n",
            "Epoch 108/600\n",
            "61/61 [==============================] - 16s 260ms/step - loss: 1.0251 - accuracy: 0.7302 - precision: 0.8355 - recall: 0.6208 - val_loss: 0.7865 - val_accuracy: 0.7238 - val_precision: 0.7609 - val_recall: 0.6667\n",
            "Epoch 109/600\n",
            "61/61 [==============================] - 16s 259ms/step - loss: 0.9254 - accuracy: 0.7556 - precision: 0.8765 - recall: 0.6505 - val_loss: 0.7621 - val_accuracy: 0.7905 - val_precision: 0.7959 - val_recall: 0.7429\n",
            "Epoch 110/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 0.8933 - accuracy: 0.7661 - precision: 0.8364 - recall: 0.6994 - val_loss: 0.8690 - val_accuracy: 0.7714 - val_precision: 0.7778 - val_recall: 0.7333\n",
            "Epoch 111/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 0.9170 - accuracy: 0.7447 - precision: 0.8699 - recall: 0.6696 - val_loss: 0.8038 - val_accuracy: 0.7524 - val_precision: 0.7677 - val_recall: 0.7238\n",
            "Epoch 112/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 1.0936 - accuracy: 0.7000 - precision: 0.8183 - recall: 0.6078 - val_loss: 0.7406 - val_accuracy: 0.7810 - val_precision: 0.7941 - val_recall: 0.7714\n",
            "Epoch 113/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 1.0625 - accuracy: 0.7165 - precision: 0.8270 - recall: 0.6342 - val_loss: 0.7470 - val_accuracy: 0.7429 - val_precision: 0.8105 - val_recall: 0.7333\n",
            "Epoch 114/600\n",
            "61/61 [==============================] - 16s 261ms/step - loss: 1.0488 - accuracy: 0.7255 - precision: 0.8321 - recall: 0.6624 - val_loss: 0.9123 - val_accuracy: 0.7333 - val_precision: 0.7895 - val_recall: 0.7143\n",
            "Epoch 115/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 1.1919 - accuracy: 0.6948 - precision: 0.8200 - recall: 0.5841 - val_loss: 0.8540 - val_accuracy: 0.7333 - val_precision: 0.7708 - val_recall: 0.7048\n",
            "Epoch 116/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 1.0800 - accuracy: 0.7210 - precision: 0.8448 - recall: 0.6137 - val_loss: 0.8709 - val_accuracy: 0.7429 - val_precision: 0.7660 - val_recall: 0.6857\n",
            "Epoch 117/600\n",
            "61/61 [==============================] - 16s 256ms/step - loss: 1.1301 - accuracy: 0.7200 - precision: 0.8371 - recall: 0.6044 - val_loss: 0.7366 - val_accuracy: 0.7619 - val_precision: 0.8172 - val_recall: 0.7238\n",
            "Epoch 118/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 1.1364 - accuracy: 0.7018 - precision: 0.8252 - recall: 0.6081 - val_loss: 0.6661 - val_accuracy: 0.7619 - val_precision: 0.7917 - val_recall: 0.7238\n",
            "Epoch 119/600\n",
            "61/61 [==============================] - 16s 262ms/step - loss: 1.2073 - accuracy: 0.6911 - precision: 0.8180 - recall: 0.5846 - val_loss: 0.7075 - val_accuracy: 0.7429 - val_precision: 0.7629 - val_recall: 0.7048\n",
            "Epoch 120/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 1.1008 - accuracy: 0.7285 - precision: 0.8795 - recall: 0.6014 - val_loss: 0.8292 - val_accuracy: 0.7143 - val_precision: 0.7708 - val_recall: 0.7048\n",
            "Epoch 121/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 1.0476 - accuracy: 0.7355 - precision: 0.8681 - recall: 0.6134 - val_loss: 0.8143 - val_accuracy: 0.7333 - val_precision: 0.7732 - val_recall: 0.7143\n",
            "Epoch 122/600\n",
            "61/61 [==============================] - 16s 256ms/step - loss: 1.0725 - accuracy: 0.7193 - precision: 0.8434 - recall: 0.6306 - val_loss: 0.6412 - val_accuracy: 0.8000 - val_precision: 0.8144 - val_recall: 0.7524\n",
            "Epoch 123/600\n",
            "61/61 [==============================] - 16s 259ms/step - loss: 1.1414 - accuracy: 0.7044 - precision: 0.8218 - recall: 0.6007 - val_loss: 0.6559 - val_accuracy: 0.7524 - val_precision: 0.8105 - val_recall: 0.7333\n",
            "Epoch 124/600\n",
            "61/61 [==============================] - 16s 263ms/step - loss: 1.2060 - accuracy: 0.6813 - precision: 0.8290 - recall: 0.5675 - val_loss: 0.6488 - val_accuracy: 0.7619 - val_precision: 0.8152 - val_recall: 0.7143\n",
            "Epoch 125/600\n",
            "61/61 [==============================] - 16s 256ms/step - loss: 1.1987 - accuracy: 0.7228 - precision: 0.8532 - recall: 0.5936 - val_loss: 0.6377 - val_accuracy: 0.7810 - val_precision: 0.7980 - val_recall: 0.7524\n",
            "Epoch 126/600\n",
            "61/61 [==============================] - 16s 256ms/step - loss: 1.1917 - accuracy: 0.7167 - precision: 0.8328 - recall: 0.5846 - val_loss: 0.7057 - val_accuracy: 0.7810 - val_precision: 0.8085 - val_recall: 0.7238\n",
            "Epoch 127/600\n",
            "61/61 [==============================] - 16s 254ms/step - loss: 0.9886 - accuracy: 0.7381 - precision: 0.8584 - recall: 0.6246 - val_loss: 0.7448 - val_accuracy: 0.7619 - val_precision: 0.8229 - val_recall: 0.7524\n",
            "Epoch 128/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 1.0664 - accuracy: 0.7215 - precision: 0.8282 - recall: 0.6507 - val_loss: 0.7298 - val_accuracy: 0.7810 - val_precision: 0.7980 - val_recall: 0.7524\n",
            "Epoch 129/600\n",
            "61/61 [==============================] - 16s 260ms/step - loss: 0.9815 - accuracy: 0.7472 - precision: 0.8300 - recall: 0.6543 - val_loss: 0.7459 - val_accuracy: 0.7810 - val_precision: 0.8085 - val_recall: 0.7238\n",
            "Epoch 130/600\n",
            "61/61 [==============================] - 16s 259ms/step - loss: 0.9793 - accuracy: 0.7497 - precision: 0.8505 - recall: 0.6355 - val_loss: 0.6940 - val_accuracy: 0.7333 - val_precision: 0.8182 - val_recall: 0.6857\n",
            "Epoch 131/600\n",
            "61/61 [==============================] - 16s 258ms/step - loss: 1.0527 - accuracy: 0.7180 - precision: 0.8465 - recall: 0.6157 - val_loss: 0.6382 - val_accuracy: 0.7905 - val_precision: 0.8750 - val_recall: 0.7333\n",
            "Epoch 132/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 1.1292 - accuracy: 0.7311 - precision: 0.8685 - recall: 0.6252 - val_loss: 0.6470 - val_accuracy: 0.7810 - val_precision: 0.8298 - val_recall: 0.7429\n",
            "Epoch 133/600\n",
            "61/61 [==============================] - 16s 256ms/step - loss: 0.9941 - accuracy: 0.7573 - precision: 0.8560 - recall: 0.6799 - val_loss: 0.6481 - val_accuracy: 0.7905 - val_precision: 0.7917 - val_recall: 0.7238\n",
            "Epoch 134/600\n",
            "61/61 [==============================] - 16s 258ms/step - loss: 0.9742 - accuracy: 0.7508 - precision: 0.8635 - recall: 0.6449 - val_loss: 0.6262 - val_accuracy: 0.7810 - val_precision: 0.8511 - val_recall: 0.7619\n",
            "Epoch 135/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 0.9780 - accuracy: 0.7358 - precision: 0.8504 - recall: 0.6333 - val_loss: 0.7519 - val_accuracy: 0.7714 - val_precision: 0.8041 - val_recall: 0.7429\n",
            "Epoch 136/600\n",
            "61/61 [==============================] - 16s 256ms/step - loss: 0.9982 - accuracy: 0.7576 - precision: 0.8335 - recall: 0.6656 - val_loss: 0.6478 - val_accuracy: 0.7810 - val_precision: 0.7917 - val_recall: 0.7238\n",
            "Epoch 137/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 0.9719 - accuracy: 0.7598 - precision: 0.8567 - recall: 0.6733 - val_loss: 0.6917 - val_accuracy: 0.7714 - val_precision: 0.8125 - val_recall: 0.7429\n",
            "Epoch 138/600\n",
            "61/61 [==============================] - 16s 261ms/step - loss: 1.1676 - accuracy: 0.7130 - precision: 0.8309 - recall: 0.5957 - val_loss: 0.6205 - val_accuracy: 0.7905 - val_precision: 0.8478 - val_recall: 0.7429\n",
            "Epoch 139/600\n",
            "61/61 [==============================] - 16s 258ms/step - loss: 1.1019 - accuracy: 0.7354 - precision: 0.8683 - recall: 0.6581 - val_loss: 0.7090 - val_accuracy: 0.7714 - val_precision: 0.8021 - val_recall: 0.7333\n",
            "Epoch 140/600\n",
            "61/61 [==============================] - 16s 260ms/step - loss: 1.0464 - accuracy: 0.7621 - precision: 0.8716 - recall: 0.6618 - val_loss: 0.7503 - val_accuracy: 0.7429 - val_precision: 0.7812 - val_recall: 0.7143\n",
            "Epoch 141/600\n",
            "61/61 [==============================] - 16s 258ms/step - loss: 0.9766 - accuracy: 0.7654 - precision: 0.8893 - recall: 0.6783 - val_loss: 0.7924 - val_accuracy: 0.7619 - val_precision: 0.7778 - val_recall: 0.7333\n",
            "Epoch 142/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 1.1148 - accuracy: 0.7241 - precision: 0.8482 - recall: 0.6153 - val_loss: 0.6278 - val_accuracy: 0.7619 - val_precision: 0.8333 - val_recall: 0.7143\n",
            "Epoch 143/600\n",
            "61/61 [==============================] - 16s 259ms/step - loss: 1.1585 - accuracy: 0.7159 - precision: 0.8433 - recall: 0.5943 - val_loss: 0.6619 - val_accuracy: 0.7714 - val_precision: 0.8172 - val_recall: 0.7238\n",
            "Epoch 144/600\n",
            "61/61 [==============================] - 16s 260ms/step - loss: 0.9985 - accuracy: 0.7474 - precision: 0.8658 - recall: 0.6685 - val_loss: 0.7143 - val_accuracy: 0.7524 - val_precision: 0.8043 - val_recall: 0.7048\n",
            "Epoch 145/600\n",
            "61/61 [==============================] - 16s 258ms/step - loss: 0.9644 - accuracy: 0.7524 - precision: 0.8268 - recall: 0.6386 - val_loss: 0.7135 - val_accuracy: 0.7810 - val_precision: 0.7941 - val_recall: 0.7714\n",
            "Epoch 146/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 1.1485 - accuracy: 0.7134 - precision: 0.8123 - recall: 0.6285 - val_loss: 0.7393 - val_accuracy: 0.7619 - val_precision: 0.7917 - val_recall: 0.7238\n",
            "Epoch 147/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 0.9380 - accuracy: 0.7667 - precision: 0.8522 - recall: 0.6841 - val_loss: 0.5805 - val_accuracy: 0.7714 - val_precision: 0.8427 - val_recall: 0.7143\n",
            "Epoch 148/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 1.0780 - accuracy: 0.7296 - precision: 0.8517 - recall: 0.6047 - val_loss: 0.6129 - val_accuracy: 0.7524 - val_precision: 0.8065 - val_recall: 0.7143\n",
            "Epoch 149/600\n",
            "61/61 [==============================] - 16s 256ms/step - loss: 0.9931 - accuracy: 0.7376 - precision: 0.8782 - recall: 0.6320 - val_loss: 0.6394 - val_accuracy: 0.8000 - val_precision: 0.8125 - val_recall: 0.7429\n",
            "Epoch 150/600\n",
            "61/61 [==============================] - 16s 258ms/step - loss: 1.1618 - accuracy: 0.7070 - precision: 0.8287 - recall: 0.6106 - val_loss: 0.5972 - val_accuracy: 0.7905 - val_precision: 0.8144 - val_recall: 0.7524\n",
            "Epoch 151/600\n",
            "61/61 [==============================] - 16s 256ms/step - loss: 0.9722 - accuracy: 0.7616 - precision: 0.8523 - recall: 0.6519 - val_loss: 0.7434 - val_accuracy: 0.7714 - val_precision: 0.8280 - val_recall: 0.7333\n",
            "Epoch 152/600\n",
            "61/61 [==============================] - 16s 254ms/step - loss: 0.9603 - accuracy: 0.7457 - precision: 0.8594 - recall: 0.6351 - val_loss: 0.7237 - val_accuracy: 0.7524 - val_precision: 0.7857 - val_recall: 0.7333\n",
            "Epoch 153/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 0.8428 - accuracy: 0.7814 - precision: 0.8668 - recall: 0.7096 - val_loss: 0.6213 - val_accuracy: 0.7905 - val_precision: 0.8316 - val_recall: 0.7524\n",
            "Epoch 154/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 1.0325 - accuracy: 0.7266 - precision: 0.8355 - recall: 0.6547 - val_loss: 0.8413 - val_accuracy: 0.7524 - val_precision: 0.7732 - val_recall: 0.7143\n",
            "Epoch 155/600\n",
            "61/61 [==============================] - 16s 266ms/step - loss: 0.9893 - accuracy: 0.7409 - precision: 0.8583 - recall: 0.6477 - val_loss: 0.7044 - val_accuracy: 0.7714 - val_precision: 0.8081 - val_recall: 0.7619\n",
            "Epoch 156/600\n",
            "61/61 [==============================] - 16s 267ms/step - loss: 0.8636 - accuracy: 0.7678 - precision: 0.8510 - recall: 0.6578 - val_loss: 0.7638 - val_accuracy: 0.7619 - val_precision: 0.7959 - val_recall: 0.7429\n",
            "Epoch 157/600\n",
            "61/61 [==============================] - 16s 267ms/step - loss: 1.0745 - accuracy: 0.7182 - precision: 0.8225 - recall: 0.6216 - val_loss: 0.7813 - val_accuracy: 0.7429 - val_precision: 0.7700 - val_recall: 0.7333\n",
            "Epoch 158/600\n",
            "61/61 [==============================] - 16s 259ms/step - loss: 0.8469 - accuracy: 0.7732 - precision: 0.8583 - recall: 0.6998 - val_loss: 0.6752 - val_accuracy: 0.8000 - val_precision: 0.8247 - val_recall: 0.7619\n",
            "Epoch 159/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 0.9278 - accuracy: 0.7831 - precision: 0.8765 - recall: 0.6777 - val_loss: 0.6822 - val_accuracy: 0.7714 - val_precision: 0.8061 - val_recall: 0.7524\n",
            "Epoch 160/600\n",
            "61/61 [==============================] - 16s 261ms/step - loss: 0.8793 - accuracy: 0.7881 - precision: 0.8654 - recall: 0.7039 - val_loss: 0.6057 - val_accuracy: 0.7714 - val_precision: 0.8061 - val_recall: 0.7524\n",
            "Epoch 161/600\n",
            "61/61 [==============================] - 16s 259ms/step - loss: 0.9840 - accuracy: 0.7461 - precision: 0.8378 - recall: 0.6581 - val_loss: 0.7189 - val_accuracy: 0.7524 - val_precision: 0.7723 - val_recall: 0.7429\n",
            "Epoch 162/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 0.9209 - accuracy: 0.7487 - precision: 0.8508 - recall: 0.6675 - val_loss: 0.6741 - val_accuracy: 0.8000 - val_precision: 0.8163 - val_recall: 0.7619\n",
            "Epoch 163/600\n",
            "61/61 [==============================] - 16s 265ms/step - loss: 0.8136 - accuracy: 0.7917 - precision: 0.8812 - recall: 0.6976 - val_loss: 0.6767 - val_accuracy: 0.7905 - val_precision: 0.8020 - val_recall: 0.7714\n",
            "Epoch 164/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 0.9039 - accuracy: 0.7531 - precision: 0.8413 - recall: 0.6812 - val_loss: 0.6385 - val_accuracy: 0.7905 - val_precision: 0.8041 - val_recall: 0.7429\n",
            "Epoch 165/600\n",
            "61/61 [==============================] - 16s 261ms/step - loss: 0.8476 - accuracy: 0.7570 - precision: 0.8819 - recall: 0.6645 - val_loss: 0.7392 - val_accuracy: 0.7810 - val_precision: 0.8061 - val_recall: 0.7524\n",
            "Epoch 166/600\n",
            "61/61 [==============================] - 16s 260ms/step - loss: 0.8711 - accuracy: 0.7933 - precision: 0.8900 - recall: 0.7285 - val_loss: 0.7867 - val_accuracy: 0.7905 - val_precision: 0.8100 - val_recall: 0.7714\n",
            "Epoch 167/600\n",
            "61/61 [==============================] - 16s 258ms/step - loss: 0.9452 - accuracy: 0.7646 - precision: 0.8602 - recall: 0.6842 - val_loss: 0.7056 - val_accuracy: 0.7714 - val_precision: 0.8247 - val_recall: 0.7619\n",
            "Epoch 168/600\n",
            "61/61 [==============================] - 16s 258ms/step - loss: 0.9196 - accuracy: 0.7613 - precision: 0.8520 - recall: 0.6779 - val_loss: 0.8280 - val_accuracy: 0.7619 - val_precision: 0.7745 - val_recall: 0.7524\n",
            "Epoch 169/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 0.9566 - accuracy: 0.7755 - precision: 0.8491 - recall: 0.7161 - val_loss: 0.7661 - val_accuracy: 0.7714 - val_precision: 0.7843 - val_recall: 0.7619\n",
            "Epoch 170/600\n",
            "61/61 [==============================] - 16s 254ms/step - loss: 0.8675 - accuracy: 0.7897 - precision: 0.8800 - recall: 0.7107 - val_loss: 0.7666 - val_accuracy: 0.7714 - val_precision: 0.8000 - val_recall: 0.7619\n",
            "Epoch 171/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.8427 - accuracy: 0.7546 - precision: 0.8630 - recall: 0.6993 - val_loss: 0.7538 - val_accuracy: 0.7333 - val_precision: 0.7426 - val_recall: 0.7143\n",
            "Epoch 172/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.9955 - accuracy: 0.7423 - precision: 0.8713 - recall: 0.6474 - val_loss: 0.8332 - val_accuracy: 0.7714 - val_precision: 0.8000 - val_recall: 0.7619\n",
            "Epoch 173/600\n",
            "61/61 [==============================] - 15s 254ms/step - loss: 0.9476 - accuracy: 0.7709 - precision: 0.8556 - recall: 0.6685 - val_loss: 0.7841 - val_accuracy: 0.7905 - val_precision: 0.8119 - val_recall: 0.7810\n",
            "Epoch 174/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.9310 - accuracy: 0.7750 - precision: 0.8586 - recall: 0.6951 - val_loss: 0.6673 - val_accuracy: 0.7810 - val_precision: 0.8144 - val_recall: 0.7524\n",
            "Epoch 175/600\n",
            "61/61 [==============================] - 15s 254ms/step - loss: 0.9544 - accuracy: 0.7617 - precision: 0.8709 - recall: 0.6987 - val_loss: 0.6964 - val_accuracy: 0.8000 - val_precision: 0.8200 - val_recall: 0.7810\n",
            "Epoch 176/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 0.7742 - accuracy: 0.8120 - precision: 0.8950 - recall: 0.7390 - val_loss: 0.5700 - val_accuracy: 0.8000 - val_precision: 0.8061 - val_recall: 0.7524\n",
            "Epoch 177/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.9395 - accuracy: 0.7798 - precision: 0.8926 - recall: 0.6874 - val_loss: 0.5222 - val_accuracy: 0.8095 - val_precision: 0.8155 - val_recall: 0.8000\n",
            "Epoch 178/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.9973 - accuracy: 0.7490 - precision: 0.8252 - recall: 0.6663 - val_loss: 0.5816 - val_accuracy: 0.8286 - val_precision: 0.8454 - val_recall: 0.7810\n",
            "Epoch 179/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.9219 - accuracy: 0.7579 - precision: 0.8461 - recall: 0.6713 - val_loss: 0.6847 - val_accuracy: 0.7810 - val_precision: 0.8200 - val_recall: 0.7810\n",
            "Epoch 180/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 0.9032 - accuracy: 0.7762 - precision: 0.8931 - recall: 0.6997 - val_loss: 0.6365 - val_accuracy: 0.7714 - val_precision: 0.7941 - val_recall: 0.7714\n",
            "Epoch 181/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7881 - accuracy: 0.7966 - precision: 0.8661 - recall: 0.7482 - val_loss: 0.6806 - val_accuracy: 0.8095 - val_precision: 0.8247 - val_recall: 0.7619\n",
            "Epoch 182/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8657 - accuracy: 0.8055 - precision: 0.8987 - recall: 0.6970 - val_loss: 0.5762 - val_accuracy: 0.8286 - val_precision: 0.8646 - val_recall: 0.7905\n",
            "Epoch 183/600\n",
            "61/61 [==============================] - 16s 260ms/step - loss: 1.0483 - accuracy: 0.7247 - precision: 0.8503 - recall: 0.6056 - val_loss: 0.6729 - val_accuracy: 0.8286 - val_precision: 0.8431 - val_recall: 0.8190\n",
            "Epoch 184/600\n",
            "61/61 [==============================] - 16s 254ms/step - loss: 1.0688 - accuracy: 0.7684 - precision: 0.8628 - recall: 0.6889 - val_loss: 0.6498 - val_accuracy: 0.8190 - val_precision: 0.8571 - val_recall: 0.8000\n",
            "Epoch 185/600\n",
            "61/61 [==============================] - 16s 254ms/step - loss: 0.8152 - accuracy: 0.7753 - precision: 0.8876 - recall: 0.7063 - val_loss: 0.6073 - val_accuracy: 0.7810 - val_precision: 0.8163 - val_recall: 0.7619\n",
            "Epoch 186/600\n",
            "61/61 [==============================] - 16s 256ms/step - loss: 0.9024 - accuracy: 0.7875 - precision: 0.8814 - recall: 0.6893 - val_loss: 0.7440 - val_accuracy: 0.8190 - val_precision: 0.8333 - val_recall: 0.8095\n",
            "Epoch 187/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 1.0265 - accuracy: 0.7176 - precision: 0.8189 - recall: 0.6519 - val_loss: 0.6762 - val_accuracy: 0.8095 - val_precision: 0.8300 - val_recall: 0.7905\n",
            "Epoch 188/600\n",
            "61/61 [==============================] - 16s 254ms/step - loss: 0.9068 - accuracy: 0.7651 - precision: 0.8569 - recall: 0.6921 - val_loss: 0.6945 - val_accuracy: 0.8000 - val_precision: 0.8182 - val_recall: 0.7714\n",
            "Epoch 189/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.9727 - accuracy: 0.7618 - precision: 0.8746 - recall: 0.6578 - val_loss: 0.8199 - val_accuracy: 0.8000 - val_precision: 0.8119 - val_recall: 0.7810\n",
            "Epoch 190/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8525 - accuracy: 0.7907 - precision: 0.8899 - recall: 0.7186 - val_loss: 0.5767 - val_accuracy: 0.7810 - val_precision: 0.8020 - val_recall: 0.7714\n",
            "Epoch 191/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 0.9500 - accuracy: 0.7486 - precision: 0.8563 - recall: 0.6520 - val_loss: 0.6604 - val_accuracy: 0.8095 - val_precision: 0.8182 - val_recall: 0.7714\n",
            "Epoch 192/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 0.9700 - accuracy: 0.7681 - precision: 0.8459 - recall: 0.6547 - val_loss: 0.6518 - val_accuracy: 0.8190 - val_precision: 0.8218 - val_recall: 0.7905\n",
            "Epoch 193/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8117 - accuracy: 0.7929 - precision: 0.8762 - recall: 0.6981 - val_loss: 0.7125 - val_accuracy: 0.7810 - val_precision: 0.8119 - val_recall: 0.7810\n",
            "Epoch 194/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.9902 - accuracy: 0.7558 - precision: 0.8368 - recall: 0.6699 - val_loss: 0.8008 - val_accuracy: 0.8095 - val_precision: 0.8317 - val_recall: 0.8000\n",
            "Epoch 195/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7733 - accuracy: 0.8034 - precision: 0.8802 - recall: 0.7451 - val_loss: 0.7202 - val_accuracy: 0.7619 - val_precision: 0.7670 - val_recall: 0.7524\n",
            "Epoch 196/600\n",
            "61/61 [==============================] - 16s 257ms/step - loss: 0.7280 - accuracy: 0.7980 - precision: 0.8919 - recall: 0.7408 - val_loss: 0.7879 - val_accuracy: 0.7905 - val_precision: 0.7961 - val_recall: 0.7810\n",
            "Epoch 197/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.8839 - accuracy: 0.7662 - precision: 0.8507 - recall: 0.6942 - val_loss: 0.8256 - val_accuracy: 0.7714 - val_precision: 0.7843 - val_recall: 0.7619\n",
            "Epoch 198/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.8598 - accuracy: 0.7955 - precision: 0.8749 - recall: 0.7254 - val_loss: 0.6760 - val_accuracy: 0.7333 - val_precision: 0.7789 - val_recall: 0.7048\n",
            "Epoch 199/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 0.8263 - accuracy: 0.7600 - precision: 0.8736 - recall: 0.6978 - val_loss: 0.6721 - val_accuracy: 0.7905 - val_precision: 0.7864 - val_recall: 0.7714\n",
            "Epoch 200/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 0.9658 - accuracy: 0.7592 - precision: 0.8442 - recall: 0.6760 - val_loss: 0.7039 - val_accuracy: 0.8000 - val_precision: 0.8020 - val_recall: 0.7714\n",
            "Epoch 201/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 0.8917 - accuracy: 0.7655 - precision: 0.8818 - recall: 0.6635 - val_loss: 0.5904 - val_accuracy: 0.8000 - val_precision: 0.8247 - val_recall: 0.7619\n",
            "Epoch 202/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.9293 - accuracy: 0.7757 - precision: 0.8386 - recall: 0.7045 - val_loss: 0.7175 - val_accuracy: 0.7714 - val_precision: 0.8061 - val_recall: 0.7524\n",
            "Epoch 203/600\n",
            "61/61 [==============================] - 16s 259ms/step - loss: 0.9852 - accuracy: 0.7496 - precision: 0.8468 - recall: 0.6777 - val_loss: 0.8068 - val_accuracy: 0.8000 - val_precision: 0.8218 - val_recall: 0.7905\n",
            "Epoch 204/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8702 - accuracy: 0.7655 - precision: 0.8654 - recall: 0.6867 - val_loss: 0.7074 - val_accuracy: 0.8000 - val_precision: 0.8119 - val_recall: 0.7810\n",
            "Epoch 205/600\n",
            "61/61 [==============================] - 15s 249ms/step - loss: 0.9197 - accuracy: 0.7639 - precision: 0.8582 - recall: 0.6451 - val_loss: 0.8436 - val_accuracy: 0.7714 - val_precision: 0.7879 - val_recall: 0.7429\n",
            "Epoch 206/600\n",
            "61/61 [==============================] - 15s 249ms/step - loss: 0.8804 - accuracy: 0.7689 - precision: 0.8458 - recall: 0.6789 - val_loss: 0.6485 - val_accuracy: 0.8095 - val_precision: 0.8182 - val_recall: 0.7714\n",
            "Epoch 207/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.8747 - accuracy: 0.7865 - precision: 0.8958 - recall: 0.6893 - val_loss: 0.5735 - val_accuracy: 0.8000 - val_precision: 0.8182 - val_recall: 0.7714\n",
            "Epoch 208/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.7698 - accuracy: 0.7818 - precision: 0.8734 - recall: 0.7025 - val_loss: 0.6397 - val_accuracy: 0.8190 - val_precision: 0.8218 - val_recall: 0.7905\n",
            "Epoch 209/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.9205 - accuracy: 0.7322 - precision: 0.8560 - recall: 0.6776 - val_loss: 0.8192 - val_accuracy: 0.7714 - val_precision: 0.7767 - val_recall: 0.7619\n",
            "Epoch 210/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.9143 - accuracy: 0.7710 - precision: 0.8581 - recall: 0.6981 - val_loss: 0.7016 - val_accuracy: 0.7905 - val_precision: 0.8137 - val_recall: 0.7905\n",
            "Epoch 211/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8464 - accuracy: 0.7677 - precision: 0.8604 - recall: 0.6922 - val_loss: 0.8042 - val_accuracy: 0.7714 - val_precision: 0.7941 - val_recall: 0.7714\n",
            "Epoch 212/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.8537 - accuracy: 0.7803 - precision: 0.8833 - recall: 0.7270 - val_loss: 0.5466 - val_accuracy: 0.8095 - val_precision: 0.8317 - val_recall: 0.8000\n",
            "Epoch 213/600\n",
            "61/61 [==============================] - 15s 249ms/step - loss: 0.8088 - accuracy: 0.7880 - precision: 0.8970 - recall: 0.7301 - val_loss: 0.6804 - val_accuracy: 0.7810 - val_precision: 0.8081 - val_recall: 0.7619\n",
            "Epoch 214/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.7788 - accuracy: 0.7783 - precision: 0.8701 - recall: 0.7041 - val_loss: 0.6548 - val_accuracy: 0.7714 - val_precision: 0.8081 - val_recall: 0.7619\n",
            "Epoch 215/600\n",
            "61/61 [==============================] - 15s 249ms/step - loss: 0.8207 - accuracy: 0.7943 - precision: 0.8747 - recall: 0.7153 - val_loss: 0.7058 - val_accuracy: 0.7905 - val_precision: 0.8247 - val_recall: 0.7619\n",
            "Epoch 216/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8468 - accuracy: 0.7719 - precision: 0.8533 - recall: 0.6891 - val_loss: 0.7368 - val_accuracy: 0.7429 - val_precision: 0.7938 - val_recall: 0.7333\n",
            "Epoch 217/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8305 - accuracy: 0.7715 - precision: 0.8674 - recall: 0.7024 - val_loss: 0.6423 - val_accuracy: 0.8095 - val_precision: 0.8300 - val_recall: 0.7905\n",
            "Epoch 218/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.8205 - accuracy: 0.7979 - precision: 0.8614 - recall: 0.7287 - val_loss: 0.9006 - val_accuracy: 0.7905 - val_precision: 0.8000 - val_recall: 0.7619\n",
            "Epoch 219/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.9484 - accuracy: 0.7451 - precision: 0.8645 - recall: 0.6541 - val_loss: 0.9713 - val_accuracy: 0.7810 - val_precision: 0.8081 - val_recall: 0.7619\n",
            "Epoch 220/600\n",
            "61/61 [==============================] - 15s 249ms/step - loss: 0.8085 - accuracy: 0.8013 - precision: 0.8794 - recall: 0.7237 - val_loss: 0.7994 - val_accuracy: 0.7905 - val_precision: 0.8119 - val_recall: 0.7810\n",
            "Epoch 221/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7197 - accuracy: 0.8179 - precision: 0.8924 - recall: 0.7441 - val_loss: 0.7837 - val_accuracy: 0.8000 - val_precision: 0.8200 - val_recall: 0.7810\n",
            "Epoch 222/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.7705 - accuracy: 0.8054 - precision: 0.8959 - recall: 0.7232 - val_loss: 0.6708 - val_accuracy: 0.7905 - val_precision: 0.8058 - val_recall: 0.7905\n",
            "Epoch 223/600\n",
            "61/61 [==============================] - 16s 256ms/step - loss: 0.7170 - accuracy: 0.8066 - precision: 0.8924 - recall: 0.7418 - val_loss: 0.7126 - val_accuracy: 0.7905 - val_precision: 0.8039 - val_recall: 0.7810\n",
            "Epoch 224/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7427 - accuracy: 0.8270 - precision: 0.9061 - recall: 0.7436 - val_loss: 0.7155 - val_accuracy: 0.7810 - val_precision: 0.8100 - val_recall: 0.7714\n",
            "Epoch 225/600\n",
            "61/61 [==============================] - 15s 249ms/step - loss: 0.8694 - accuracy: 0.8075 - precision: 0.8758 - recall: 0.6993 - val_loss: 0.8887 - val_accuracy: 0.7429 - val_precision: 0.7723 - val_recall: 0.7429\n",
            "Epoch 226/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.8797 - accuracy: 0.8066 - precision: 0.8902 - recall: 0.7406 - val_loss: 0.7407 - val_accuracy: 0.8000 - val_precision: 0.8182 - val_recall: 0.7714\n",
            "Epoch 227/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.6297 - accuracy: 0.8323 - precision: 0.9087 - recall: 0.7546 - val_loss: 0.7598 - val_accuracy: 0.7905 - val_precision: 0.8039 - val_recall: 0.7810\n",
            "Epoch 228/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.8790 - accuracy: 0.7499 - precision: 0.8500 - recall: 0.6677 - val_loss: 0.8176 - val_accuracy: 0.8000 - val_precision: 0.8283 - val_recall: 0.7810\n",
            "Epoch 229/600\n",
            "61/61 [==============================] - 15s 249ms/step - loss: 0.9734 - accuracy: 0.7576 - precision: 0.8323 - recall: 0.7070 - val_loss: 0.8854 - val_accuracy: 0.7714 - val_precision: 0.7822 - val_recall: 0.7524\n",
            "Epoch 230/600\n",
            "61/61 [==============================] - 15s 249ms/step - loss: 0.9159 - accuracy: 0.7674 - precision: 0.8444 - recall: 0.6706 - val_loss: 0.8052 - val_accuracy: 0.7810 - val_precision: 0.8000 - val_recall: 0.7619\n",
            "Epoch 231/600\n",
            "61/61 [==============================] - 15s 249ms/step - loss: 0.8407 - accuracy: 0.7714 - precision: 0.8480 - recall: 0.7119 - val_loss: 0.8924 - val_accuracy: 0.8000 - val_precision: 0.8119 - val_recall: 0.7810\n",
            "Epoch 232/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.9821 - accuracy: 0.7523 - precision: 0.8523 - recall: 0.6990 - val_loss: 1.0246 - val_accuracy: 0.7810 - val_precision: 0.8039 - val_recall: 0.7810\n",
            "Epoch 233/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.9367 - accuracy: 0.7914 - precision: 0.8634 - recall: 0.7152 - val_loss: 0.9785 - val_accuracy: 0.7524 - val_precision: 0.7700 - val_recall: 0.7333\n",
            "Epoch 234/600\n",
            "61/61 [==============================] - 15s 249ms/step - loss: 0.7603 - accuracy: 0.8192 - precision: 0.8969 - recall: 0.7553 - val_loss: 0.7559 - val_accuracy: 0.8000 - val_precision: 0.8100 - val_recall: 0.7714\n",
            "Epoch 235/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.7692 - accuracy: 0.7915 - precision: 0.8830 - recall: 0.7265 - val_loss: 0.6940 - val_accuracy: 0.7810 - val_precision: 0.8119 - val_recall: 0.7810\n",
            "Epoch 236/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8761 - accuracy: 0.8093 - precision: 0.8814 - recall: 0.7297 - val_loss: 0.8822 - val_accuracy: 0.7905 - val_precision: 0.8100 - val_recall: 0.7714\n",
            "Epoch 237/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.7408 - accuracy: 0.8099 - precision: 0.8994 - recall: 0.7594 - val_loss: 0.7762 - val_accuracy: 0.8000 - val_precision: 0.8163 - val_recall: 0.7619\n",
            "Epoch 238/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.7397 - accuracy: 0.8233 - precision: 0.9102 - recall: 0.7240 - val_loss: 0.8269 - val_accuracy: 0.7810 - val_precision: 0.8265 - val_recall: 0.7714\n",
            "Epoch 239/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.7912 - accuracy: 0.7900 - precision: 0.8855 - recall: 0.7183 - val_loss: 0.8185 - val_accuracy: 0.7619 - val_precision: 0.7745 - val_recall: 0.7524\n",
            "Epoch 240/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.7516 - accuracy: 0.8015 - precision: 0.8647 - recall: 0.7418 - val_loss: 0.8068 - val_accuracy: 0.7714 - val_precision: 0.7788 - val_recall: 0.7714\n",
            "Epoch 241/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7529 - accuracy: 0.7916 - precision: 0.8805 - recall: 0.7333 - val_loss: 0.7045 - val_accuracy: 0.8095 - val_precision: 0.8173 - val_recall: 0.8095\n",
            "Epoch 242/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.8199 - accuracy: 0.7960 - precision: 0.8861 - recall: 0.7090 - val_loss: 0.8830 - val_accuracy: 0.7429 - val_precision: 0.7700 - val_recall: 0.7333\n",
            "Epoch 243/600\n",
            "61/61 [==============================] - 16s 256ms/step - loss: 0.7924 - accuracy: 0.7876 - precision: 0.8852 - recall: 0.7227 - val_loss: 0.8705 - val_accuracy: 0.8000 - val_precision: 0.8235 - val_recall: 0.8000\n",
            "Epoch 244/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7935 - accuracy: 0.7813 - precision: 0.8579 - recall: 0.7086 - val_loss: 0.8190 - val_accuracy: 0.7714 - val_precision: 0.7767 - val_recall: 0.7619\n",
            "Epoch 245/600\n",
            "61/61 [==============================] - 15s 249ms/step - loss: 0.7462 - accuracy: 0.7993 - precision: 0.9102 - recall: 0.7180 - val_loss: 0.8250 - val_accuracy: 0.8000 - val_precision: 0.8137 - val_recall: 0.7905\n",
            "Epoch 246/600\n",
            "61/61 [==============================] - 15s 249ms/step - loss: 0.9175 - accuracy: 0.7943 - precision: 0.8681 - recall: 0.7276 - val_loss: 0.7303 - val_accuracy: 0.7905 - val_precision: 0.8283 - val_recall: 0.7810\n",
            "Epoch 247/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.9848 - accuracy: 0.7724 - precision: 0.8871 - recall: 0.6887 - val_loss: 0.8896 - val_accuracy: 0.7524 - val_precision: 0.7778 - val_recall: 0.7333\n",
            "Epoch 248/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8695 - accuracy: 0.7761 - precision: 0.8724 - recall: 0.7353 - val_loss: 0.7576 - val_accuracy: 0.8190 - val_precision: 0.8469 - val_recall: 0.7905\n",
            "Epoch 249/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8712 - accuracy: 0.7783 - precision: 0.8841 - recall: 0.6949 - val_loss: 0.7342 - val_accuracy: 0.8286 - val_precision: 0.8317 - val_recall: 0.8000\n",
            "Epoch 250/600\n",
            "61/61 [==============================] - 15s 248ms/step - loss: 0.7697 - accuracy: 0.7823 - precision: 0.8829 - recall: 0.7288 - val_loss: 0.6931 - val_accuracy: 0.7905 - val_precision: 0.8404 - val_recall: 0.7524\n",
            "Epoch 251/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 1.0032 - accuracy: 0.7766 - precision: 0.8673 - recall: 0.7050 - val_loss: 0.8516 - val_accuracy: 0.7810 - val_precision: 0.8333 - val_recall: 0.7619\n",
            "Epoch 252/600\n",
            "61/61 [==============================] - 15s 249ms/step - loss: 0.8098 - accuracy: 0.8064 - precision: 0.8964 - recall: 0.7458 - val_loss: 0.7823 - val_accuracy: 0.7619 - val_precision: 0.7812 - val_recall: 0.7143\n",
            "Epoch 253/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8472 - accuracy: 0.7807 - precision: 0.8684 - recall: 0.6994 - val_loss: 0.7724 - val_accuracy: 0.8000 - val_precision: 0.8265 - val_recall: 0.7714\n",
            "Epoch 254/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7526 - accuracy: 0.7912 - precision: 0.8936 - recall: 0.7168 - val_loss: 0.8043 - val_accuracy: 0.8095 - val_precision: 0.8384 - val_recall: 0.7905\n",
            "Epoch 255/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.7418 - accuracy: 0.8132 - precision: 0.8914 - recall: 0.7353 - val_loss: 0.7664 - val_accuracy: 0.8000 - val_precision: 0.7961 - val_recall: 0.7810\n",
            "Epoch 256/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8091 - accuracy: 0.7869 - precision: 0.8625 - recall: 0.7306 - val_loss: 0.9346 - val_accuracy: 0.7810 - val_precision: 0.7885 - val_recall: 0.7810\n",
            "Epoch 257/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.8795 - accuracy: 0.7897 - precision: 0.8674 - recall: 0.7293 - val_loss: 0.6929 - val_accuracy: 0.8190 - val_precision: 0.8300 - val_recall: 0.7905\n",
            "Epoch 258/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7780 - accuracy: 0.8072 - precision: 0.8791 - recall: 0.7281 - val_loss: 0.7281 - val_accuracy: 0.8000 - val_precision: 0.8100 - val_recall: 0.7714\n",
            "Epoch 259/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.7428 - accuracy: 0.7976 - precision: 0.8771 - recall: 0.7350 - val_loss: 0.7797 - val_accuracy: 0.7810 - val_precision: 0.8265 - val_recall: 0.7714\n",
            "Epoch 260/600\n",
            "61/61 [==============================] - 15s 249ms/step - loss: 0.7949 - accuracy: 0.8117 - precision: 0.8967 - recall: 0.7240 - val_loss: 0.7735 - val_accuracy: 0.7810 - val_precision: 0.7961 - val_recall: 0.7810\n",
            "Epoch 261/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7188 - accuracy: 0.8101 - precision: 0.8857 - recall: 0.7568 - val_loss: 0.8384 - val_accuracy: 0.7619 - val_precision: 0.7980 - val_recall: 0.7524\n",
            "Epoch 262/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.6533 - accuracy: 0.8328 - precision: 0.9207 - recall: 0.7746 - val_loss: 0.8174 - val_accuracy: 0.7429 - val_precision: 0.7576 - val_recall: 0.7143\n",
            "Epoch 263/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7694 - accuracy: 0.8083 - precision: 0.8790 - recall: 0.7288 - val_loss: 0.9791 - val_accuracy: 0.7524 - val_precision: 0.7624 - val_recall: 0.7333\n",
            "Epoch 264/600\n",
            "61/61 [==============================] - 16s 258ms/step - loss: 0.7492 - accuracy: 0.8038 - precision: 0.8719 - recall: 0.7366 - val_loss: 0.8606 - val_accuracy: 0.7619 - val_precision: 0.7980 - val_recall: 0.7524\n",
            "Epoch 265/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.7803 - accuracy: 0.7938 - precision: 0.8991 - recall: 0.7351 - val_loss: 0.8063 - val_accuracy: 0.7619 - val_precision: 0.7980 - val_recall: 0.7524\n",
            "Epoch 266/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.8176 - accuracy: 0.7821 - precision: 0.8735 - recall: 0.6991 - val_loss: 0.9420 - val_accuracy: 0.7714 - val_precision: 0.7921 - val_recall: 0.7619\n",
            "Epoch 267/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.6988 - accuracy: 0.7999 - precision: 0.8853 - recall: 0.7524 - val_loss: 0.9646 - val_accuracy: 0.7810 - val_precision: 0.7941 - val_recall: 0.7714\n",
            "Epoch 268/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.7491 - accuracy: 0.8122 - precision: 0.8963 - recall: 0.7592 - val_loss: 0.7597 - val_accuracy: 0.7905 - val_precision: 0.8058 - val_recall: 0.7905\n",
            "Epoch 269/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.9195 - accuracy: 0.7648 - precision: 0.8875 - recall: 0.6800 - val_loss: 0.7727 - val_accuracy: 0.7905 - val_precision: 0.8119 - val_recall: 0.7810\n",
            "Epoch 270/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7992 - accuracy: 0.7840 - precision: 0.8757 - recall: 0.7216 - val_loss: 0.8061 - val_accuracy: 0.7905 - val_precision: 0.7961 - val_recall: 0.7810\n",
            "Epoch 271/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.6529 - accuracy: 0.8382 - precision: 0.9034 - recall: 0.7790 - val_loss: 0.6268 - val_accuracy: 0.8286 - val_precision: 0.8400 - val_recall: 0.8000\n",
            "Epoch 272/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.7181 - accuracy: 0.8321 - precision: 0.9169 - recall: 0.7745 - val_loss: 0.9650 - val_accuracy: 0.8000 - val_precision: 0.8020 - val_recall: 0.7714\n",
            "Epoch 273/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7223 - accuracy: 0.8311 - precision: 0.8817 - recall: 0.7744 - val_loss: 0.6894 - val_accuracy: 0.7905 - val_precision: 0.8058 - val_recall: 0.7905\n",
            "Epoch 274/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.6980 - accuracy: 0.8245 - precision: 0.9066 - recall: 0.7839 - val_loss: 0.8413 - val_accuracy: 0.7619 - val_precision: 0.7822 - val_recall: 0.7524\n",
            "Epoch 275/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 0.7368 - accuracy: 0.8079 - precision: 0.8879 - recall: 0.7619 - val_loss: 0.7801 - val_accuracy: 0.8000 - val_precision: 0.7961 - val_recall: 0.7810\n",
            "Epoch 276/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8068 - accuracy: 0.7931 - precision: 0.8776 - recall: 0.7211 - val_loss: 0.8287 - val_accuracy: 0.7810 - val_precision: 0.8100 - val_recall: 0.7714\n",
            "Epoch 277/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.6943 - accuracy: 0.8200 - precision: 0.8965 - recall: 0.7413 - val_loss: 0.7650 - val_accuracy: 0.8190 - val_precision: 0.8416 - val_recall: 0.8095\n",
            "Epoch 278/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.6509 - accuracy: 0.8225 - precision: 0.8861 - recall: 0.7813 - val_loss: 0.8057 - val_accuracy: 0.7714 - val_precision: 0.7864 - val_recall: 0.7714\n",
            "Epoch 279/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8557 - accuracy: 0.8001 - precision: 0.8870 - recall: 0.7324 - val_loss: 0.7887 - val_accuracy: 0.8095 - val_precision: 0.8218 - val_recall: 0.7905\n",
            "Epoch 280/600\n",
            "61/61 [==============================] - 15s 254ms/step - loss: 0.8051 - accuracy: 0.8103 - precision: 0.8933 - recall: 0.7534 - val_loss: 0.8058 - val_accuracy: 0.8286 - val_precision: 0.8235 - val_recall: 0.8000\n",
            "Epoch 281/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7024 - accuracy: 0.8209 - precision: 0.8983 - recall: 0.7691 - val_loss: 0.8221 - val_accuracy: 0.7714 - val_precision: 0.7788 - val_recall: 0.7714\n",
            "Epoch 282/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.7028 - accuracy: 0.8255 - precision: 0.8958 - recall: 0.7743 - val_loss: 0.7096 - val_accuracy: 0.8190 - val_precision: 0.8350 - val_recall: 0.8190\n",
            "Epoch 283/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.6623 - accuracy: 0.8393 - precision: 0.9297 - recall: 0.7944 - val_loss: 0.8736 - val_accuracy: 0.8000 - val_precision: 0.8235 - val_recall: 0.8000\n",
            "Epoch 284/600\n",
            "61/61 [==============================] - 16s 260ms/step - loss: 0.6721 - accuracy: 0.8420 - precision: 0.9060 - recall: 0.7778 - val_loss: 0.9273 - val_accuracy: 0.8000 - val_precision: 0.8077 - val_recall: 0.8000\n",
            "Epoch 285/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.6429 - accuracy: 0.8309 - precision: 0.9018 - recall: 0.7979 - val_loss: 0.8430 - val_accuracy: 0.8000 - val_precision: 0.8119 - val_recall: 0.7810\n",
            "Epoch 286/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7770 - accuracy: 0.8288 - precision: 0.9027 - recall: 0.7518 - val_loss: 0.8901 - val_accuracy: 0.8095 - val_precision: 0.8155 - val_recall: 0.8000\n",
            "Epoch 287/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.7077 - accuracy: 0.8238 - precision: 0.9136 - recall: 0.7621 - val_loss: 0.8806 - val_accuracy: 0.7905 - val_precision: 0.7885 - val_recall: 0.7810\n",
            "Epoch 288/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7215 - accuracy: 0.8178 - precision: 0.8823 - recall: 0.7719 - val_loss: 0.7745 - val_accuracy: 0.7810 - val_precision: 0.8081 - val_recall: 0.7619\n",
            "Epoch 289/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7942 - accuracy: 0.8151 - precision: 0.8755 - recall: 0.7397 - val_loss: 0.9893 - val_accuracy: 0.7810 - val_precision: 0.7961 - val_recall: 0.7810\n",
            "Epoch 290/600\n",
            "61/61 [==============================] - 16s 256ms/step - loss: 0.7345 - accuracy: 0.8216 - precision: 0.8767 - recall: 0.7932 - val_loss: 0.7150 - val_accuracy: 0.8000 - val_precision: 0.7981 - val_recall: 0.7905\n",
            "Epoch 291/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.6623 - accuracy: 0.8392 - precision: 0.8986 - recall: 0.7899 - val_loss: 0.7936 - val_accuracy: 0.8190 - val_precision: 0.8485 - val_recall: 0.8000\n",
            "Epoch 292/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.6538 - accuracy: 0.8538 - precision: 0.9192 - recall: 0.7823 - val_loss: 0.8970 - val_accuracy: 0.8000 - val_precision: 0.8218 - val_recall: 0.7905\n",
            "Epoch 293/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7304 - accuracy: 0.8151 - precision: 0.8743 - recall: 0.7388 - val_loss: 0.9157 - val_accuracy: 0.7619 - val_precision: 0.7879 - val_recall: 0.7429\n",
            "Epoch 294/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7903 - accuracy: 0.8056 - precision: 0.8709 - recall: 0.7424 - val_loss: 0.8739 - val_accuracy: 0.7905 - val_precision: 0.7885 - val_recall: 0.7810\n",
            "Epoch 295/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7741 - accuracy: 0.7981 - precision: 0.8647 - recall: 0.7317 - val_loss: 1.0016 - val_accuracy: 0.7619 - val_precision: 0.7843 - val_recall: 0.7619\n",
            "Epoch 296/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.6670 - accuracy: 0.8155 - precision: 0.8945 - recall: 0.7704 - val_loss: 1.0095 - val_accuracy: 0.7524 - val_precision: 0.7778 - val_recall: 0.7333\n",
            "Epoch 297/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.6156 - accuracy: 0.8258 - precision: 0.9035 - recall: 0.7540 - val_loss: 0.7549 - val_accuracy: 0.8000 - val_precision: 0.8351 - val_recall: 0.7714\n",
            "Epoch 298/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.5946 - accuracy: 0.8347 - precision: 0.9096 - recall: 0.7733 - val_loss: 0.8076 - val_accuracy: 0.7905 - val_precision: 0.8058 - val_recall: 0.7905\n",
            "Epoch 299/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.7240 - accuracy: 0.8236 - precision: 0.8864 - recall: 0.7672 - val_loss: 0.8318 - val_accuracy: 0.7810 - val_precision: 0.8119 - val_recall: 0.7810\n",
            "Epoch 300/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.6737 - accuracy: 0.8343 - precision: 0.9094 - recall: 0.7652 - val_loss: 1.0621 - val_accuracy: 0.7905 - val_precision: 0.7941 - val_recall: 0.7714\n",
            "Epoch 301/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.5948 - accuracy: 0.8506 - precision: 0.9166 - recall: 0.8054 - val_loss: 1.0759 - val_accuracy: 0.7714 - val_precision: 0.7714 - val_recall: 0.7714\n",
            "Epoch 302/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.7658 - accuracy: 0.8130 - precision: 0.8840 - recall: 0.7424 - val_loss: 0.9982 - val_accuracy: 0.7810 - val_precision: 0.7810 - val_recall: 0.7810\n",
            "Epoch 303/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.8416 - accuracy: 0.7896 - precision: 0.8401 - recall: 0.7353 - val_loss: 1.0489 - val_accuracy: 0.7429 - val_precision: 0.7723 - val_recall: 0.7429\n",
            "Epoch 304/600\n",
            "61/61 [==============================] - 16s 258ms/step - loss: 0.6313 - accuracy: 0.8383 - precision: 0.9250 - recall: 0.7919 - val_loss: 0.9203 - val_accuracy: 0.7810 - val_precision: 0.7843 - val_recall: 0.7619\n",
            "Epoch 305/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.6966 - accuracy: 0.8296 - precision: 0.9026 - recall: 0.7816 - val_loss: 0.9526 - val_accuracy: 0.8000 - val_precision: 0.8200 - val_recall: 0.7810\n",
            "Epoch 306/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7226 - accuracy: 0.8137 - precision: 0.9061 - recall: 0.7392 - val_loss: 1.0374 - val_accuracy: 0.7619 - val_precision: 0.7600 - val_recall: 0.7238\n",
            "Epoch 307/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7563 - accuracy: 0.7859 - precision: 0.8813 - recall: 0.7252 - val_loss: 0.7055 - val_accuracy: 0.8190 - val_precision: 0.8300 - val_recall: 0.7905\n",
            "Epoch 308/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.8479 - accuracy: 0.7751 - precision: 0.8903 - recall: 0.7247 - val_loss: 0.8523 - val_accuracy: 0.7619 - val_precision: 0.7677 - val_recall: 0.7238\n",
            "Epoch 309/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.8138 - accuracy: 0.8225 - precision: 0.9106 - recall: 0.7666 - val_loss: 0.8635 - val_accuracy: 0.7905 - val_precision: 0.8039 - val_recall: 0.7810\n",
            "Epoch 310/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7424 - accuracy: 0.8377 - precision: 0.9034 - recall: 0.7709 - val_loss: 0.6938 - val_accuracy: 0.7714 - val_precision: 0.7900 - val_recall: 0.7524\n",
            "Epoch 311/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7668 - accuracy: 0.8266 - precision: 0.8995 - recall: 0.7693 - val_loss: 0.7681 - val_accuracy: 0.8000 - val_precision: 0.8119 - val_recall: 0.7810\n",
            "Epoch 312/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.8979 - accuracy: 0.7984 - precision: 0.8860 - recall: 0.7466 - val_loss: 0.7567 - val_accuracy: 0.7905 - val_precision: 0.7921 - val_recall: 0.7619\n",
            "Epoch 313/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7569 - accuracy: 0.8220 - precision: 0.8894 - recall: 0.7393 - val_loss: 0.8669 - val_accuracy: 0.7714 - val_precision: 0.7788 - val_recall: 0.7714\n",
            "Epoch 314/600\n",
            "61/61 [==============================] - 15s 250ms/step - loss: 0.7246 - accuracy: 0.8062 - precision: 0.8932 - recall: 0.7596 - val_loss: 0.6149 - val_accuracy: 0.7810 - val_precision: 0.7941 - val_recall: 0.7714\n",
            "Epoch 315/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7161 - accuracy: 0.8048 - precision: 0.8912 - recall: 0.7657 - val_loss: 0.7845 - val_accuracy: 0.7905 - val_precision: 0.7864 - val_recall: 0.7714\n",
            "Epoch 316/600\n",
            "61/61 [==============================] - 16s 254ms/step - loss: 0.7620 - accuracy: 0.8155 - precision: 0.8982 - recall: 0.7510 - val_loss: 0.9376 - val_accuracy: 0.7905 - val_precision: 0.8058 - val_recall: 0.7905\n",
            "Epoch 317/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.5888 - accuracy: 0.8111 - precision: 0.8691 - recall: 0.7800 - val_loss: 1.1088 - val_accuracy: 0.7333 - val_precision: 0.7308 - val_recall: 0.7238\n",
            "Epoch 318/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.7924 - accuracy: 0.7907 - precision: 0.8661 - recall: 0.7425 - val_loss: 1.0630 - val_accuracy: 0.8000 - val_precision: 0.7961 - val_recall: 0.7810\n",
            "Epoch 319/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.6905 - accuracy: 0.8361 - precision: 0.8960 - recall: 0.7819 - val_loss: 1.0132 - val_accuracy: 0.7619 - val_precision: 0.7647 - val_recall: 0.7429\n",
            "Epoch 320/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7727 - accuracy: 0.8027 - precision: 0.8990 - recall: 0.7156 - val_loss: 1.1079 - val_accuracy: 0.7714 - val_precision: 0.7900 - val_recall: 0.7524\n",
            "Epoch 321/600\n",
            "61/61 [==============================] - 16s 254ms/step - loss: 0.6831 - accuracy: 0.8428 - precision: 0.9011 - recall: 0.7650 - val_loss: 0.9208 - val_accuracy: 0.8000 - val_precision: 0.8039 - val_recall: 0.7810\n",
            "Epoch 322/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7827 - accuracy: 0.8234 - precision: 0.8696 - recall: 0.7605 - val_loss: 0.7492 - val_accuracy: 0.7810 - val_precision: 0.8081 - val_recall: 0.7619\n",
            "Epoch 323/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.7679 - accuracy: 0.7845 - precision: 0.8565 - recall: 0.7098 - val_loss: 0.8706 - val_accuracy: 0.8000 - val_precision: 0.8100 - val_recall: 0.7714\n",
            "Epoch 324/600\n",
            "61/61 [==============================] - 16s 260ms/step - loss: 0.7302 - accuracy: 0.8329 - precision: 0.8981 - recall: 0.7649 - val_loss: 0.7090 - val_accuracy: 0.7810 - val_precision: 0.7980 - val_recall: 0.7524\n",
            "Epoch 325/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.7017 - accuracy: 0.8097 - precision: 0.8772 - recall: 0.7403 - val_loss: 0.8128 - val_accuracy: 0.7429 - val_precision: 0.7549 - val_recall: 0.7333\n",
            "Epoch 326/600\n",
            "61/61 [==============================] - 16s 254ms/step - loss: 0.7289 - accuracy: 0.8177 - precision: 0.8973 - recall: 0.7641 - val_loss: 0.8562 - val_accuracy: 0.7714 - val_precision: 0.7723 - val_recall: 0.7429\n",
            "Epoch 327/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.6809 - accuracy: 0.8381 - precision: 0.8891 - recall: 0.7904 - val_loss: 0.8432 - val_accuracy: 0.7714 - val_precision: 0.7800 - val_recall: 0.7429\n",
            "Epoch 328/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.7282 - accuracy: 0.8001 - precision: 0.8936 - recall: 0.7514 - val_loss: 0.8645 - val_accuracy: 0.7810 - val_precision: 0.7843 - val_recall: 0.7619\n",
            "Epoch 329/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7074 - accuracy: 0.8260 - precision: 0.8939 - recall: 0.7642 - val_loss: 1.0595 - val_accuracy: 0.7905 - val_precision: 0.7961 - val_recall: 0.7810\n",
            "Epoch 330/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.7072 - accuracy: 0.8188 - precision: 0.8849 - recall: 0.7558 - val_loss: 0.9693 - val_accuracy: 0.7905 - val_precision: 0.8039 - val_recall: 0.7810\n",
            "Epoch 331/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.6833 - accuracy: 0.8311 - precision: 0.9023 - recall: 0.7612 - val_loss: 0.9139 - val_accuracy: 0.7524 - val_precision: 0.7647 - val_recall: 0.7429\n",
            "Epoch 332/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.9172 - accuracy: 0.8087 - precision: 0.8803 - recall: 0.7260 - val_loss: 0.9924 - val_accuracy: 0.7810 - val_precision: 0.7864 - val_recall: 0.7714\n",
            "Epoch 333/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.8499 - accuracy: 0.7892 - precision: 0.8659 - recall: 0.7384 - val_loss: 0.9272 - val_accuracy: 0.7714 - val_precision: 0.7864 - val_recall: 0.7714\n",
            "Epoch 334/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7212 - accuracy: 0.7759 - precision: 0.8516 - recall: 0.7277 - val_loss: 0.9512 - val_accuracy: 0.7714 - val_precision: 0.7843 - val_recall: 0.7619\n",
            "Epoch 335/600\n",
            "61/61 [==============================] - 16s 254ms/step - loss: 0.7232 - accuracy: 0.8160 - precision: 0.8879 - recall: 0.7725 - val_loss: 0.8554 - val_accuracy: 0.7619 - val_precision: 0.7767 - val_recall: 0.7619\n",
            "Epoch 336/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.7416 - accuracy: 0.8060 - precision: 0.8800 - recall: 0.7403 - val_loss: 0.7575 - val_accuracy: 0.7905 - val_precision: 0.8021 - val_recall: 0.7333\n",
            "Epoch 337/600\n",
            "61/61 [==============================] - 16s 260ms/step - loss: 0.7348 - accuracy: 0.8123 - precision: 0.8861 - recall: 0.7389 - val_loss: 0.8226 - val_accuracy: 0.8000 - val_precision: 0.7941 - val_recall: 0.7714\n",
            "Epoch 338/600\n",
            "61/61 [==============================] - 16s 258ms/step - loss: 0.6770 - accuracy: 0.7923 - precision: 0.8720 - recall: 0.7501 - val_loss: 1.0750 - val_accuracy: 0.7333 - val_precision: 0.7600 - val_recall: 0.7238\n",
            "Epoch 339/600\n",
            "61/61 [==============================] - 16s 259ms/step - loss: 0.6748 - accuracy: 0.8171 - precision: 0.9063 - recall: 0.7440 - val_loss: 1.0416 - val_accuracy: 0.7619 - val_precision: 0.7767 - val_recall: 0.7619\n",
            "Epoch 340/600\n",
            "61/61 [==============================] - 16s 259ms/step - loss: 0.7145 - accuracy: 0.8361 - precision: 0.9013 - recall: 0.7715 - val_loss: 0.9691 - val_accuracy: 0.7619 - val_precision: 0.7767 - val_recall: 0.7619\n",
            "Epoch 341/600\n",
            "61/61 [==============================] - 16s 256ms/step - loss: 0.6558 - accuracy: 0.8521 - precision: 0.9096 - recall: 0.7890 - val_loss: 0.8276 - val_accuracy: 0.7905 - val_precision: 0.8000 - val_recall: 0.7619\n",
            "Epoch 342/600\n",
            "61/61 [==============================] - 16s 259ms/step - loss: 0.7698 - accuracy: 0.8270 - precision: 0.9047 - recall: 0.7418 - val_loss: 0.8395 - val_accuracy: 0.7714 - val_precision: 0.8000 - val_recall: 0.7619\n",
            "Epoch 343/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 0.7146 - accuracy: 0.8110 - precision: 0.8956 - recall: 0.7526 - val_loss: 1.0618 - val_accuracy: 0.7905 - val_precision: 0.8041 - val_recall: 0.7429\n",
            "Epoch 344/600\n",
            "61/61 [==============================] - 16s 263ms/step - loss: 0.6329 - accuracy: 0.8476 - precision: 0.9270 - recall: 0.7887 - val_loss: 0.8972 - val_accuracy: 0.7905 - val_precision: 0.7981 - val_recall: 0.7905\n",
            "Epoch 345/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 0.7548 - accuracy: 0.8135 - precision: 0.8895 - recall: 0.7445 - val_loss: 1.0298 - val_accuracy: 0.7429 - val_precision: 0.7647 - val_recall: 0.7429\n",
            "Epoch 346/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 0.9519 - accuracy: 0.7776 - precision: 0.8535 - recall: 0.7176 - val_loss: 0.9814 - val_accuracy: 0.7810 - val_precision: 0.8000 - val_recall: 0.7619\n",
            "Epoch 347/600\n",
            "61/61 [==============================] - 16s 258ms/step - loss: 0.7817 - accuracy: 0.8119 - precision: 0.8865 - recall: 0.7580 - val_loss: 0.9416 - val_accuracy: 0.7619 - val_precision: 0.7745 - val_recall: 0.7524\n",
            "Epoch 348/600\n",
            "61/61 [==============================] - 16s 256ms/step - loss: 0.6609 - accuracy: 0.8149 - precision: 0.8788 - recall: 0.7602 - val_loss: 1.0670 - val_accuracy: 0.7429 - val_precision: 0.7647 - val_recall: 0.7429\n",
            "Epoch 349/600\n",
            "61/61 [==============================] - 15s 252ms/step - loss: 0.9974 - accuracy: 0.8040 - precision: 0.8987 - recall: 0.7152 - val_loss: 0.9287 - val_accuracy: 0.7524 - val_precision: 0.7800 - val_recall: 0.7429\n",
            "Epoch 350/600\n",
            "61/61 [==============================] - 16s 254ms/step - loss: 0.7617 - accuracy: 0.8166 - precision: 0.8981 - recall: 0.7307 - val_loss: 0.8419 - val_accuracy: 0.7714 - val_precision: 0.7921 - val_recall: 0.7619\n",
            "Epoch 351/600\n",
            "61/61 [==============================] - 15s 253ms/step - loss: 0.8195 - accuracy: 0.8022 - precision: 0.8963 - recall: 0.7235 - val_loss: 0.8404 - val_accuracy: 0.7810 - val_precision: 0.7745 - val_recall: 0.7524\n",
            "Epoch 352/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 0.6524 - accuracy: 0.8305 - precision: 0.9000 - recall: 0.7822 - val_loss: 0.8711 - val_accuracy: 0.7714 - val_precision: 0.7843 - val_recall: 0.7619\n",
            "Epoch 353/600\n",
            "61/61 [==============================] - 16s 255ms/step - loss: 0.6055 - accuracy: 0.8469 - precision: 0.9204 - recall: 0.7893 - val_loss: 1.0101 - val_accuracy: 0.7429 - val_precision: 0.7677 - val_recall: 0.7238\n",
            "Epoch 354/600\n",
            "61/61 [==============================] - 16s 254ms/step - loss: 0.7562 - accuracy: 0.7971 - precision: 0.8919 - recall: 0.7457 - val_loss: 1.0978 - val_accuracy: 0.7619 - val_precision: 0.7647 - val_recall: 0.7429\n",
            "Epoch 355/600\n",
            "61/61 [==============================] - 15s 251ms/step - loss: 0.6678 - accuracy: 0.8430 - precision: 0.8977 - recall: 0.8072 - val_loss: 0.7488 - val_accuracy: 0.8190 - val_precision: 0.8137 - val_recall: 0.7905\n",
            "\n",
            "We have reached 81.03% recall, so we will stopping training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSBOv-Ed803n"
      },
      "source": [
        "# Testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKJ3JbQuybl-",
        "outputId": "5037c10e-eb38-427e-9590-34df066c6766"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\r\n",
        "def classify(img_path):\r\n",
        "    img = image.load_img(img_path, target_size=(224, 224, 3))\r\n",
        "    img_array = image.img_to_array(img)\r\n",
        "    img_array =img_array/255\r\n",
        "    img_batch = np.expand_dims(img_array, axis=0)\r\n",
        "    prediction = model.predict(img_batch)\r\n",
        "    print(np.argmax(prediction))\r\n",
        "    print(prediction)\r\n",
        "\r\n",
        "#Coloque o caminho da imagem \r\n",
        "img_path=\"165.jpg\"\r\n",
        "classify(img_path)\r\n",
        "label_map = (train_generator.class_indices)\r\n",
        "print(label_map)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "[[1.0000000e+00 1.0050030e-13 1.1344114e-11 3.6869010e-12 7.8114439e-11\n",
            "  6.0537487e-16 5.2726738e-28 1.9533331e-10]]\n",
            "{'Araruta': 0, 'Beldroegão': 1, 'Capiçoba': 2, 'Capuchina': 3, 'Caruru': 4, 'Ora-pro-nóbis': 5, 'Peixinho': 6, 'Taioba': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqmkGdcBzwcx"
      },
      "source": [
        "# Fine Tunning\r\n",
        "\r\n",
        "> Após finalizar o treino do topo do modelo, o resultado pode ser melhorado ao habilitar o treinamento de todas as suas camadas e realizar novamente o treino da rede, o qual deverá ser feito com um baixo Learning rate. Com isso, promove-se o ajuste fino do modelo.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZjqchPRzMlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb05d6c-6284-4854-e77b-8b1919e81f4c"
      },
      "source": [
        "#Reinicia os parâmetros do treino\n",
        "train_generator.reset()\n",
        "validation_generator.reset()\n",
        "\n",
        "#Habilita o treinamento de todas as camadas\n",
        "for layer in model.layers:\n",
        "\tlayer.trainable = True\n",
        "\n",
        "#Configura o treino com um Learning rate baixo\n",
        "model.summary()\n",
        "opt = SGD(lr=1e-4, momentum=0.9)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer=opt, metrics=['accuracy','Precision','Recall'])\n",
        "history = model.fit(train_generator, epochs=50, validation_data = validation_generator, verbose = 1,class_weight=class_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 40,414,024\n",
            "Trainable params: 40,414,024\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "61/61 [==============================] - 24s 343ms/step - loss: 3.5008 - accuracy: 0.4898 - precision: 0.5780 - recall: 0.3798 - val_loss: 1.4099 - val_accuracy: 0.4667 - val_precision: 0.7000 - val_recall: 0.2667\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 20s 318ms/step - loss: 2.8647 - accuracy: 0.3783 - precision: 0.6249 - recall: 0.2444 - val_loss: 2.8901 - val_accuracy: 0.4667 - val_precision: 0.5128 - val_recall: 0.3810\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 19s 316ms/step - loss: 3.4373 - accuracy: 0.4063 - precision: 0.6165 - recall: 0.2394 - val_loss: 2.1714 - val_accuracy: 0.4857 - val_precision: 0.6111 - val_recall: 0.4190\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 20s 318ms/step - loss: 2.6840 - accuracy: 0.4637 - precision: 0.6642 - recall: 0.3186 - val_loss: 1.8624 - val_accuracy: 0.4095 - val_precision: 0.6757 - val_recall: 0.2381\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 20s 319ms/step - loss: 3.8843 - accuracy: 0.4200 - precision: 0.7434 - recall: 0.2463 - val_loss: 1.1718 - val_accuracy: 0.5333 - val_precision: 0.7600 - val_recall: 0.3619\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 19s 315ms/step - loss: 2.4783 - accuracy: 0.4992 - precision: 0.7020 - recall: 0.3461 - val_loss: 1.8350 - val_accuracy: 0.5524 - val_precision: 0.6375 - val_recall: 0.4857\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 19s 318ms/step - loss: 2.5742 - accuracy: 0.5039 - precision: 0.7499 - recall: 0.3404 - val_loss: 0.9612 - val_accuracy: 0.6952 - val_precision: 0.9091 - val_recall: 0.4762\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 19s 310ms/step - loss: 2.0706 - accuracy: 0.5424 - precision: 0.7982 - recall: 0.3946 - val_loss: 1.1546 - val_accuracy: 0.5048 - val_precision: 0.9000 - val_recall: 0.3429\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 19s 312ms/step - loss: 1.8860 - accuracy: 0.5426 - precision: 0.7852 - recall: 0.3897 - val_loss: 1.0496 - val_accuracy: 0.6571 - val_precision: 0.7763 - val_recall: 0.5619\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 19s 311ms/step - loss: 2.1002 - accuracy: 0.5641 - precision: 0.7284 - recall: 0.4265 - val_loss: 1.0723 - val_accuracy: 0.6762 - val_precision: 0.7808 - val_recall: 0.5429\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 19s 308ms/step - loss: 1.6493 - accuracy: 0.6150 - precision: 0.8324 - recall: 0.4860 - val_loss: 1.5206 - val_accuracy: 0.7143 - val_precision: 0.8378 - val_recall: 0.5905\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 19s 309ms/step - loss: 1.7495 - accuracy: 0.6587 - precision: 0.7998 - recall: 0.5116 - val_loss: 1.4271 - val_accuracy: 0.7333 - val_precision: 0.8095 - val_recall: 0.6476\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 19s 317ms/step - loss: 1.6026 - accuracy: 0.6752 - precision: 0.8208 - recall: 0.5567 - val_loss: 0.9860 - val_accuracy: 0.7905 - val_precision: 0.8444 - val_recall: 0.7238\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 19s 310ms/step - loss: 1.4949 - accuracy: 0.6940 - precision: 0.8268 - recall: 0.5695 - val_loss: 3.6691 - val_accuracy: 0.7429 - val_precision: 0.7677 - val_recall: 0.7238\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 19s 310ms/step - loss: 1.3430 - accuracy: 0.7377 - precision: 0.8545 - recall: 0.6429 - val_loss: 0.5778 - val_accuracy: 0.8571 - val_precision: 0.8866 - val_recall: 0.8190\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 19s 308ms/step - loss: 1.2200 - accuracy: 0.7782 - precision: 0.8503 - recall: 0.7120 - val_loss: 1.2219 - val_accuracy: 0.7619 - val_precision: 0.7895 - val_recall: 0.7143\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 19s 309ms/step - loss: 1.1269 - accuracy: 0.7713 - precision: 0.8578 - recall: 0.6502 - val_loss: 0.7862 - val_accuracy: 0.8000 - val_precision: 0.8265 - val_recall: 0.7714\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 19s 310ms/step - loss: 1.0685 - accuracy: 0.7880 - precision: 0.8485 - recall: 0.6979 - val_loss: 1.4594 - val_accuracy: 0.7810 - val_precision: 0.7879 - val_recall: 0.7429\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 19s 310ms/step - loss: 1.2804 - accuracy: 0.7421 - precision: 0.8315 - recall: 0.6673 - val_loss: 0.5693 - val_accuracy: 0.8000 - val_precision: 0.8333 - val_recall: 0.7143\n",
            "Epoch 20/50\n",
            "61/61 [==============================] - 19s 311ms/step - loss: 0.9417 - accuracy: 0.7889 - precision: 0.8781 - recall: 0.6876 - val_loss: 0.9054 - val_accuracy: 0.8667 - val_precision: 0.9239 - val_recall: 0.8095\n",
            "Epoch 21/50\n",
            "61/61 [==============================] - 19s 307ms/step - loss: 1.1617 - accuracy: 0.8226 - precision: 0.8800 - recall: 0.7544 - val_loss: 0.5551 - val_accuracy: 0.8762 - val_precision: 0.8812 - val_recall: 0.8476\n",
            "Epoch 22/50\n",
            "61/61 [==============================] - 19s 311ms/step - loss: 0.9999 - accuracy: 0.8302 - precision: 0.8806 - recall: 0.7891 - val_loss: 1.0618 - val_accuracy: 0.8381 - val_precision: 0.8447 - val_recall: 0.8286\n",
            "Epoch 23/50\n",
            "61/61 [==============================] - 19s 307ms/step - loss: 1.0161 - accuracy: 0.8298 - precision: 0.8858 - recall: 0.7812 - val_loss: 0.6686 - val_accuracy: 0.8571 - val_precision: 0.8866 - val_recall: 0.8190\n",
            "Epoch 24/50\n",
            "61/61 [==============================] - 19s 306ms/step - loss: 0.9291 - accuracy: 0.8617 - precision: 0.9081 - recall: 0.8024 - val_loss: 1.1169 - val_accuracy: 0.8381 - val_precision: 0.8830 - val_recall: 0.7905\n",
            "Epoch 25/50\n",
            "61/61 [==============================] - 19s 308ms/step - loss: 0.8046 - accuracy: 0.8669 - precision: 0.9324 - recall: 0.8123 - val_loss: 1.1229 - val_accuracy: 0.8857 - val_precision: 0.8846 - val_recall: 0.8762\n",
            "Epoch 26/50\n",
            "61/61 [==============================] - 19s 310ms/step - loss: 0.7969 - accuracy: 0.8728 - precision: 0.9027 - recall: 0.8367 - val_loss: 0.9913 - val_accuracy: 0.8286 - val_precision: 0.8317 - val_recall: 0.8000\n",
            "Epoch 27/50\n",
            "61/61 [==============================] - 19s 307ms/step - loss: 1.0384 - accuracy: 0.8635 - precision: 0.9141 - recall: 0.8360 - val_loss: 0.4971 - val_accuracy: 0.8857 - val_precision: 0.9029 - val_recall: 0.8857\n",
            "Epoch 28/50\n",
            "61/61 [==============================] - 19s 306ms/step - loss: 0.7275 - accuracy: 0.9040 - precision: 0.9292 - recall: 0.8750 - val_loss: 0.5798 - val_accuracy: 0.8857 - val_precision: 0.8900 - val_recall: 0.8476\n",
            "Epoch 29/50\n",
            "61/61 [==============================] - 19s 310ms/step - loss: 0.8544 - accuracy: 0.8778 - precision: 0.9090 - recall: 0.8450 - val_loss: 0.9056 - val_accuracy: 0.8095 - val_precision: 0.8173 - val_recall: 0.8095\n",
            "Epoch 30/50\n",
            "61/61 [==============================] - 19s 309ms/step - loss: 0.7748 - accuracy: 0.8954 - precision: 0.9095 - recall: 0.8828 - val_loss: 0.6374 - val_accuracy: 0.9333 - val_precision: 0.9417 - val_recall: 0.9238\n",
            "Epoch 31/50\n",
            "61/61 [==============================] - 19s 307ms/step - loss: 1.0761 - accuracy: 0.8983 - precision: 0.9171 - recall: 0.8696 - val_loss: 0.8294 - val_accuracy: 0.8667 - val_precision: 0.8824 - val_recall: 0.8571\n",
            "Epoch 32/50\n",
            "61/61 [==============================] - 19s 315ms/step - loss: 0.8152 - accuracy: 0.8979 - precision: 0.9175 - recall: 0.8869 - val_loss: 0.6439 - val_accuracy: 0.9238 - val_precision: 0.9231 - val_recall: 0.9143\n",
            "Epoch 33/50\n",
            "61/61 [==============================] - 20s 320ms/step - loss: 0.9832 - accuracy: 0.8721 - precision: 0.9000 - recall: 0.8497 - val_loss: 0.6083 - val_accuracy: 0.9429 - val_precision: 0.9515 - val_recall: 0.9333\n",
            "Epoch 34/50\n",
            "61/61 [==============================] - 20s 326ms/step - loss: 0.6095 - accuracy: 0.9164 - precision: 0.9430 - recall: 0.9055 - val_loss: 0.9222 - val_accuracy: 0.8952 - val_precision: 0.8952 - val_recall: 0.8952\n",
            "Epoch 35/50\n",
            "61/61 [==============================] - 19s 316ms/step - loss: 0.5097 - accuracy: 0.9110 - precision: 0.9322 - recall: 0.8961 - val_loss: 2.5372 - val_accuracy: 0.8381 - val_precision: 0.8462 - val_recall: 0.8381\n",
            "Epoch 36/50\n",
            "61/61 [==============================] - 19s 311ms/step - loss: 0.9569 - accuracy: 0.9047 - precision: 0.9202 - recall: 0.8897 - val_loss: 0.6345 - val_accuracy: 0.8762 - val_precision: 0.8846 - val_recall: 0.8762\n",
            "Epoch 37/50\n",
            "61/61 [==============================] - 19s 311ms/step - loss: 0.4886 - accuracy: 0.9097 - precision: 0.9328 - recall: 0.9005 - val_loss: 1.9487 - val_accuracy: 0.8190 - val_precision: 0.8269 - val_recall: 0.8190\n",
            "Epoch 38/50\n",
            "61/61 [==============================] - 19s 317ms/step - loss: 0.6615 - accuracy: 0.9097 - precision: 0.9211 - recall: 0.9061 - val_loss: 0.9542 - val_accuracy: 0.9048 - val_precision: 0.9126 - val_recall: 0.8952\n",
            "Epoch 39/50\n",
            "61/61 [==============================] - 19s 317ms/step - loss: 0.5708 - accuracy: 0.9445 - precision: 0.9476 - recall: 0.9342 - val_loss: 2.3232 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333\n",
            "Epoch 40/50\n",
            "61/61 [==============================] - 19s 315ms/step - loss: 0.4293 - accuracy: 0.9403 - precision: 0.9477 - recall: 0.9322 - val_loss: 2.8728 - val_accuracy: 0.8571 - val_precision: 0.8654 - val_recall: 0.8571\n",
            "Epoch 41/50\n",
            "61/61 [==============================] - 19s 313ms/step - loss: 0.5776 - accuracy: 0.9520 - precision: 0.9565 - recall: 0.9448 - val_loss: 1.0634 - val_accuracy: 0.8762 - val_precision: 0.8750 - val_recall: 0.8667\n",
            "Epoch 42/50\n",
            "61/61 [==============================] - 19s 314ms/step - loss: 0.5312 - accuracy: 0.9484 - precision: 0.9521 - recall: 0.9343 - val_loss: 0.7796 - val_accuracy: 0.9048 - val_precision: 0.9135 - val_recall: 0.9048\n",
            "Epoch 43/50\n",
            "61/61 [==============================] - 20s 322ms/step - loss: 0.5222 - accuracy: 0.9417 - precision: 0.9506 - recall: 0.9376 - val_loss: 1.9404 - val_accuracy: 0.8381 - val_precision: 0.8381 - val_recall: 0.8381\n",
            "Epoch 44/50\n",
            "61/61 [==============================] - 19s 316ms/step - loss: 0.4438 - accuracy: 0.9382 - precision: 0.9434 - recall: 0.9364 - val_loss: 0.8782 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
            "Epoch 45/50\n",
            "61/61 [==============================] - 20s 320ms/step - loss: 0.6195 - accuracy: 0.9602 - precision: 0.9629 - recall: 0.9602 - val_loss: 0.7159 - val_accuracy: 0.9143 - val_precision: 0.9231 - val_recall: 0.9143\n",
            "Epoch 46/50\n",
            "61/61 [==============================] - 19s 310ms/step - loss: 0.5883 - accuracy: 0.9417 - precision: 0.9475 - recall: 0.9393 - val_loss: 2.5075 - val_accuracy: 0.8667 - val_precision: 0.8750 - val_recall: 0.8667\n",
            "Epoch 47/50\n",
            "61/61 [==============================] - 19s 312ms/step - loss: 0.6031 - accuracy: 0.9533 - precision: 0.9556 - recall: 0.9470 - val_loss: 1.6288 - val_accuracy: 0.8952 - val_precision: 0.8942 - val_recall: 0.8857\n",
            "Epoch 48/50\n",
            "61/61 [==============================] - 19s 314ms/step - loss: 0.4577 - accuracy: 0.9394 - precision: 0.9450 - recall: 0.9358 - val_loss: 1.5561 - val_accuracy: 0.8762 - val_precision: 0.8932 - val_recall: 0.8762\n",
            "Epoch 49/50\n",
            "61/61 [==============================] - 19s 312ms/step - loss: 0.7066 - accuracy: 0.9423 - precision: 0.9438 - recall: 0.9414 - val_loss: 1.8189 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048\n",
            "Epoch 50/50\n",
            "61/61 [==============================] - 19s 311ms/step - loss: 0.5698 - accuracy: 0.9371 - precision: 0.9447 - recall: 0.9365 - val_loss: 2.5547 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5-RY0ZcluvP"
      },
      "source": [
        "# Testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeoCPhF6l291",
        "outputId": "98258892-cb34-44eb-97ac-6803463fb84a"
      },
      "source": [
        "classify(\"613.jpg\")\r\n",
        "label_map = (train_generator.class_indices)\r\n",
        "print(label_map)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "[[1.6270591e-38 0.0000000e+00 0.0000000e+00 1.0000000e+00 4.7836879e-31\n",
            "  0.0000000e+00 0.0000000e+00 2.3057504e-17]]\n",
            "{'Araruta': 0, 'Beldroegão': 1, 'Capiçoba': 2, 'Capuchina': 3, 'Caruru': 4, 'Ora-pro-nóbis': 5, 'Peixinho': 6, 'Taioba': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dku29oGZCykD"
      },
      "source": [
        "# Gerar arquivo tflite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dKw41uMyQi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0c2df4-3f76-4ea6-87d1-1f210318bbd0"
      },
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('vgg16_CAF.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpyh525ace/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpyh525ace/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w22CSDG8C5eD"
      },
      "source": [
        "# Resultados do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va4W-QNE8iol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "ed46b2fb-1e69-458f-d262-8a5cda84ab78"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['recall']\n",
        "val_acc = history.history['val_recall']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training recall')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation recall')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}